ACTIVATION = "tanh"  # Default "relu"
SOLVER = "adam"  # Default "ADAM"
ALPHA = 0.0001  # Default 0.0001
BATCH_SIZE = "auto"  # Default "AUTO"
LEARNING_RATE = "adaptive"  # Default "CONSTANT"
LEARNING_RATE_INIT = 0.001  # Default 0.001
POWER_T = 0.5  # Default 0.5
MAX_ITER = 100  # Default 200
SHUFFLE = True  # Default True
RANDOM_STATE = 0  # Default None
TOL = 0.0001  # Default 0.0001
VERBOSE = False  # Default False
WARM_START = False  # Default False
MOMENTUM = 0.9  # Default 0.9
NESTEROVS_MOMENTUM = True  # Default True
EARLY_STOPPING = False  # Default False
VALIDATION_FRACTION = 0.1  # Default 0.1
BETA_1 = 0.9  # Default 0.9
BETA_2 = 0.999  # Default 0.999
EPSILON = 1e-08  # Default 1e-08
N_ITER_NO_CHANGE = 10  # Default 10
