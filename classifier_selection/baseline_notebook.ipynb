{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy\n",
    "#!{sys.executable} -m pip install numpy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#!{sys.executable} -m pip install sklearn\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_summary = 3\n",
    "project_keys = [\"HTTPCLIENT\", \"LUCENE\", \"JCR\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    raw_data = []\n",
    "    data_directory = \"..\" + os.path.sep + \"data\"\n",
    "    for filename in os.listdir(data_directory):\n",
    "        with codecs.open(data_directory + os.path.sep + filename, \"r\", \"utf-8\") as fin:\n",
    "            raw_data += json.load(fin)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_corpus_labels(raw_data):\n",
    "    # Corpus building.\n",
    "    corpus = []\n",
    "    labels = []\n",
    "    n_bug = 0\n",
    "    for n_file in raw_data:\n",
    "\n",
    "        txt = \"\"\n",
    "        for i in range(boost_summary):\n",
    "            txt += n_file[\"summary\"] + \" \"\n",
    "\n",
    "        corpus.append(txt + \" \" + n_file[\"description\"])\n",
    "        labels.append(n_file[\"label\"])\n",
    "        if n_file[\"label\"] == \"BUG\":\n",
    "            n_bug += 1\n",
    "    print(f\"{n_bug} BUG / {len(labels)} \\n\")\n",
    "    return corpus, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_computing(corpus, labels, vectorizer, feature_selection = True, k_best=30000):\n",
    "    # TF-IDF.\n",
    "    print(\"Feature computing.\")\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "    print(f\"\\t{X.shape[1]} features.\")\n",
    "\n",
    "    if feature_selection:\n",
    "        print(\"Extracting %d best features by a chi-squared test\" % k_best)\n",
    "        ch2 = SelectKBest(chi2, k=k_best)\n",
    "        X = ch2.fit_transform(X, labels)\n",
    "\n",
    "        #if feature_names:  # keep selected feature names.\n",
    "        #    feature_names = [feature_names[i] for i in ch2.get_support(indices=True)]\n",
    "        return X, vectorizer, ch2\n",
    "\n",
    "    return X, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data by project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_data_by_project(raw_data, stemmer=None):\n",
    "    # Create dicts of tickets for each project\n",
    "    dict_data_split = {}\n",
    "    print(\"Split data for each project\")\n",
    "    for project_key in project_keys:\n",
    "        dict_data_split[project_key] = {}\n",
    "        dict_data_split[project_key][\"tickets\"] = []\n",
    "        dict_data_split[project_key][\"corpus\"] = []\n",
    "        dict_data_split[project_key][\"labels\"] = []\n",
    "\n",
    "    for ticket in raw_data:\n",
    "        for project_key in project_keys:\n",
    "            if project_key in ticket[\"key\"]:\n",
    "                dict_data_split[project_key][\"tickets\"].append(ticket)\n",
    "\n",
    "    for project_key in project_keys:\n",
    "        print(\"Get corpus and labels for project: \", project_key)\n",
    "        tickets = dict_data_split[project_key][\"tickets\"]\n",
    "        # Get corpus and labels for specific project tickets\n",
    "        if stemmer is not None:\n",
    "            corpus, labels = get_corpus_labels(tickets)\n",
    "        else:\n",
    "            corpus, labels = get_corpus_labels(tickets)\n",
    "        dict_data_split[project_key][\"corpus\"] = corpus\n",
    "        dict_data_split[project_key][\"labels\"] = labels\n",
    "\n",
    "    return dict_data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def labels_binarizing(labels):\n",
    "    lb = LabelBinarizer()\n",
    "    # Binarize labels with BUG = 0 and NBUG = 1\n",
    "    labels = numpy.array([number[0] for number in lb.fit_transform(labels)])\n",
    "    # Inverse 0 and 1 to have good labels, i.e BUG = 1 and NBUG = 0\n",
    "    return numpy.logical_not(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_scoring(X, binarized_labels, clf, cv=10):\n",
    "    scores = cross_val_score(clf, X, binarized_labels, cv=cv, scoring='accuracy')\n",
    "    print(\"Accuracy: %0.3f\" % scores.mean())\n",
    "    print(\"95%% Confidence Interval +/- %0.3f\" % (scores.std() * 2))\n",
    "    print(\"Standard deviation: %0.3f\\n\" % scores.std())\n",
    "    \n",
    "    scores = cross_val_score(clf, X, binarized_labels, cv=cv, scoring='f1')\n",
    "    print(\"F1score: %0.3f\" % scores.mean())\n",
    "    print(\"95%% Confidence Interval +/- %0.3f\" % (scores.std() * 2))\n",
    "    print(\"Standard deviation: %0.3f\\n\" % scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_multilayer_perceptron(raw_data):\n",
    "    corpus, labels = get_corpus_labels(raw_data)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), stop_words={\"english\"},  sublinear_tf=True)\n",
    "    mlp = MLPClassifier(activation='tanh', learning_rate='adaptive', max_iter=100, random_state=0)\n",
    "    X, vectorizer, chi = feature_computing(corpus, labels, vectorizer, feature_selection=True)\n",
    "    binarized_labels = labels_binarizing(labels)\n",
    "\n",
    "    print(\"=====> Scoring MLP <=====\")\n",
    "    make_scoring(X,binarized_labels,mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "Feature computing.\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "=====> Scoring MLP Accuracy <=====\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data()\n",
    "score_multilayer_perceptron(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_stochastic_gradient_descent(raw_data):\n",
    "    corpus, labels = get_corpus_labels(raw_data)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), stop_words={\"english\"},  sublinear_tf=True)\n",
    "    sgd = SGDClassifier(random_state=0, loss='modified_huber', max_iter=5000)\n",
    "    X, vectorizer, chi = feature_computing(corpus, labels, vectorizer, feature_selection=True)\n",
    "    binarized_labels = labels_binarizing(labels)\n",
    "\n",
    "    print(\"=====> Scoring SGD <=====\")\n",
    "    make_scoring(X, binarized_labels, sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "Feature computing.\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "=====> Scoring SGD Accuracy <=====\n",
      "Accuracy: 0.894\n",
      "95% Confidence Interval +/- 0.029\n",
      "Standard deviation: 0.015\n",
      "\n",
      "F1score: 0.841\n",
      "95% Confidence Interval +/- 0.037\n",
      "Standard deviation: 0.019\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data()\n",
    "score_stochastic_gradient_descent(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_svm(raw_data):\n",
    "    corpus, labels = get_corpus_labels(raw_data)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), stop_words={\"english\"},  sublinear_tf=True)\n",
    "    svm = SVC(C=100, gamma='scale')\n",
    "    X, vectorizer, chi = feature_computing(corpus, labels, vectorizer, feature_selection=True)\n",
    "    binarized_labels = labels_binarizing(labels)\n",
    "\n",
    "    print(\"=====> Scoring SVM <=====\")\n",
    "    make_scoring(X, binarized_labels, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "raw_data = load_data()\n",
    "score_svm(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_random_forest(raw_data):\n",
    "    corpus, labels = get_corpus_labels(raw_data)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), stop_words={\"english\"},  sublinear_tf=True)\n",
    "    rf = RandomForestClassifier(n_estimators=20, random_state=0, criterion='entropy')\n",
    "    X, vectorizer, chi = feature_computing(corpus, labels, vectorizer, feature_selection=True)\n",
    "    binarized_labels = labels_binarizing(labels)\n",
    "\n",
    "    print(\"=====> Scoring RF <=====\")\n",
    "    make_scoring(X, binarized_labels, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "Feature computing.\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "=====> Scoring RF Accuracy <=====\n",
      "Accuracy: 0.787\n",
      "95% Confidence Interval +/- 0.033\n",
      "Standard deviation: 0.017\n",
      "\n",
      "F1score: 0.610\n",
      "95% Confidence Interval +/- 0.089\n",
      "Standard deviation: 0.044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data()\n",
    "score_random_forest(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_ridge_classifier(raw_data):\n",
    "    corpus, labels = get_corpus_labels(raw_data)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), stop_words={\"english\"},  sublinear_tf=True)\n",
    "    rrc = RidgeClassifier(random_state=0)\n",
    "    X, vectorizer, chi = feature_computing(corpus, labels, vectorizer, feature_selection=True)\n",
    "    binarized_labels = labels_binarizing(labels)\n",
    "\n",
    "    print(\"=====> Scoring RRC <=====\")\n",
    "    make_scoring(X, binarized_labels, rrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "Feature computing.\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "=====> Scoring RRC Accuracy <=====\n",
      "Accuracy: 0.882\n",
      "95% Confidence Interval +/- 0.030\n",
      "Standard deviation: 0.015\n",
      "\n",
      "F1score: 0.819\n",
      "95% Confidence Interval +/- 0.050\n",
      "Standard deviation: 0.025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data()\n",
    "score_ridge_classifier(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_knn(raw_data):\n",
    "    corpus, labels = get_corpus_labels(raw_data)\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, ngram_range=(1, 3), stop_words={\"english\"},  sublinear_tf=True)\n",
    "    knn = KNeighborsClassifier(weights='distance', n_neighbors=2)\n",
    "    X, vectorizer, chi = feature_computing(corpus, labels, vectorizer, feature_selection=True)\n",
    "    binarized_labels = labels_binarizing(labels)\n",
    "\n",
    "    print(\"=====> Scoring KNN <=====\")\n",
    "    make_scoring(X, binarized_labels, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940 BUG / 5591 \n",
      "\n",
      "Feature computing.\n",
      "\t99349 features.\n",
      "Extracting 30000 best features by a chi-squared test\n",
      "=====> Scoring KNN Accuracy <=====\n",
      "Accuracy: 0.671\n",
      "95% Confidence Interval +/- 0.018\n",
      "Standard deviation: 0.009\n",
      "\n",
      "F1score: 0.108\n",
      "95% Confidence Interval +/- 0.090\n",
      "Standard deviation: 0.045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_data()\n",
    "score_knn(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}