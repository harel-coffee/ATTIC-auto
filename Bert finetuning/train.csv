label,summarydescription
1,"DefaultMethodRetryHandler bug. DefaultMethodRetryHandler does not seem to test correctly for the number of
attempts to retry a given method. It seems to bail out one attempt too early:

if (executionCount >= this.retryCount) {
  // Do not retry if over max retry count
  return false;
}

For example, if I set the retryCount to 1, HttpClient does not retry the method
at all. At least that's what I'm seeing when I step through it with a debugger."
1,"Not configuring the adminId, anonymousId, or defaultuserId causes login module to ignore credentials. Using the DefaultLoginModule, DefaultAccessManager, and DefaultSecurityManager and calling Repository.login(Credentials) causes the following stack trace to be thrown.  

javax.jcr.LoginException: LoginModule ignored Credentials: LoginModule ignored Credentials: LoginModule ignored Credentials
	at org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1353)
	at org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:53)
	at com.cerner.system.configuration.repository.jcr.JackrabbitTest.testLoginWithCredentials(JackrabbitTest.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:59)
	at org.junit.internal.runners.MethodRoadie.runTestMethod(MethodRoadie.java:98)
	at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:79)
	at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:87)
	at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:77)
	at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:42)
	at org.junit.internal.runners.JUnit4ClassRunner.invokeTestMethod(JUnit4ClassRunner.java:88)
	at org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)
	at org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)
	at org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)
Caused by: javax.security.auth.login.FailedLoginException: LoginModule ignored Credentials
	at org.apache.jackrabbit.core.security.authentication.LocalAuthContext.login(LocalAuthContext.java:73)
	at org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1346)
	... 24 more
javax.security.auth.login.FailedLoginException: LoginModule ignored Credentials
	at org.apache.jackrabbit.core.security.authentication.LocalAuthContext.login(LocalAuthContext.java:73)
	at org.apache.jackrabbit.core.RepositoryImpl.login(RepositoryImpl.java:1346)
	at org.apache.jackrabbit.commons.AbstractRepository.login(AbstractRepository.java:53)
	at com.cerner.system.configuration.repository.jcr.JackrabbitTest.testLoginWithCredentials(JackrabbitTest.java:23)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:585)
	at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:59)
	at org.junit.internal.runners.MethodRoadie.runTestMethod(MethodRoadie.java:98)
	at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:79)
	at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:87)
	at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:77)
	at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:42)
	at org.junit.internal.runners.JUnit4ClassRunner.invokeTestMethod(JUnit4ClassRunner.java:88)
	at org.junit.internal.runners.JUnit4ClassRunner.runMethods(JUnit4ClassRunner.java:51)
	at org.junit.internal.runners.JUnit4ClassRunner$1.run(JUnit4ClassRunner.java:44)
	at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:27)
	at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:37)
	at org.junit.internal.runners.JUnit4ClassRunner.run(JUnit4ClassRunner.java:42)
	at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:45)
	at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:460)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:673)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:386)
	at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:196)

A testcase and repository.xml file will be attached shortly."
1,"Node removal fails with AccessDeniedException. I have a hierarchy of nodes which are all access controllable. The following hierarchy illustrates the setup for my problem.
root  -  read permissions to everyone
  | - subFolder  -  all permissions to user A
        | - subsubFolder  -  all permissions to user A

The user A has all rights from the node ""subFolder"" downwards.

I tried to remove the node ""subsubFolder"" with the user A. Clearly A has enough permissions to remove the node. But as soon as I call Session.save() an AccessDeniedException is thrown.

I did a lot of debugging and found a possible cause for this fault. It led me to the function ACLProvider.AclPermissions.buildResult(). All line references are based on the source code in the subversion repository found here: http://svn.apache.org/viewvc/jackrabbit/tags/1.6.0/jackrabbit-core/src/main/java/org/apache/jackrabbit/core/security/authorization/acl/ACLProvider.java?view=markup.
On line 458 Jackrabbit collects all access control entries of the node, that I want to remove, and all its parents and puts it in the variable ""entries"". In my example this variable contains three entries:
1. all permissions to user A
2. all permissions to user A
3. read permissions to everyone
On lines 460 - 466 it collects all access control entries of the node, that I want to remove, and puts it in ""localACEs"". This variable contains one entry: all permissions to user A.
If I want to be able to remove ""subsubFolder"", user A needs the permission from the parent node. The permissions of the parent nodes of ""subsubFolder"" are: all permissions to user A and read permissions to everyone. But that's where the access check fails. In line 488 Jackrabbit checks if a permission from ""entries"" is local or not by looking it up in ""localACEs"". If it is in there, the permission is local, else not. Unfortunately it recognizes the permission of the node ""subFolder"" as local. Thus the permissions of the parent nodes of ""subsubFolder"" are: read permissions to everyone. So I cannot remove the node.
The source of the error is the equals check of the access control entries. The permissions of node ""subFolder"" are considered equal to the one of ""subsubFolder"". If I explicitly assign the permission ""remove node permission to user A"" to the node ""subFolder"", it works fine, because it is recognized as parent permission."
1,"SSL verification occurs before setSoTimeout, which can lead to hangs. partial thread dump:

       at java.net.SocketInputStream.socketRead0(Native Method)
       at java.net.SocketInputStream.read(SocketInputStream.java:129)
       at com.sun.net.ssl.internal.ssl.InputRecord.readFully(InputRecord.java:293)
       at com.sun.net.ssl.internal.ssl.InputRecord.read(InputRecord.java:331)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:723)
       - locked <0x00002aaab87d9de0> (a java.lang.Object)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1030)
       - locked <0x00002aaab87d9dc0> (a java.lang.Object)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1057)
       at com.sun.net.ssl.internal.ssl.SSLSocketImpl.getSession(SSLSocketImpl.java:1757)
       at org.apache.http.conn.ssl.AbstractVerifier.verify(AbstractVerifier.java:87)
       at org.apache.http.conn.ssl.SSLSocketFactory.connectSocket(SSLSocketFactory.java:295)
       at org.apache.http.impl.conn.DefaultClientConnectionOperator.openConnection(DefaultClientConnectionOperator.java:131)
       at org.apache.http.impl.conn.AbstractPoolEntry.open(AbstractPoolEntry.java:143)
       at org.apache.http.impl.conn.AbstractPooledConnAdapter.open(AbstractPooledConnAdapter.java:120)
       at org.apache.http.impl.client.DefaultClientRequestDirector.execute(DefaultClientRequestDirector.java:286)
       at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:452)
       at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:406)
       at org.apache.http.impl.client.AbstractHttpClient.execute(AbstractHttpClient.java:365)


... this is because in DefaultClientConnectionOperator, prepareSocket (which sets any configured timeouts) isn't called until after SocketFactory.connectSocket. When using SSLSocketFactory, the default behavior is to verify the hostname, which opens a connection, and can block indefinitely.

Simple workaround is to use the AllowAllHostnameVerifier which doesn't do any verification."
1,"JCR2SPI: VersionHistoryImpl.getQLabels() needs to skip jcr:mixinTypes as well. getQLabels() iterates through the properties on a version labels node to compute the set of labels. Currently it only ignores jcr:primaryType, but it needs to skip jcr:mixinTypes as well.
"
1,"VirtualItemStates of node types definitions not accessible with uuid. The VirtualNodeTypeStateProvider that maps node type definitions into the workspace under /jcr:system/jcr:nodeTypes does not implement the methods:

- internalGetNodeState(NodeId id)
- internalHasNodeState(NodeId id)

This has the effect that ItemStates that reflect node type definitions are not accessible directly with their uuid."
1,"Malformed excerpt if content contains markup and no highlights found. Any markup in content that is used in an excerpt is encoded with corresponding entity references. However, this process is broken when there are no highlights in the excerpt. In this case, the content is provided as is in the excerpt, which may lead to malformed HTML/XML."
1,"Concurrency issues in SegmentInfo.files() could lead to ConcurrentModificationException. The multi-threaded call of the files() in SegmentInfo could lead to the ConcurrentModificationException if one thread is not finished additions to the ArrayList (files) yet while the other thread already obtained it as cached (see below). This is a rare exception, but it would be nice to fix. I see the code is no longer problematic in the trunk (and others ported from flex_1458), looks it was fixed while implementing post 3.x features. The fix to 3.x and 2.9.x branches could be the same - create the files set first and populate it, and then assign to the member variable at the end of the method. This will resolve the issue. I could prepare the patch for 2.9.4 and 3.x, if needed.

--

INFO: [19] webapp= path=/replication params={command=fetchindex&wt=javabin} status=0 QTime=1
Jul 30, 2010 9:13:05 AM org.apache.solr.core.SolrCore execute
INFO: [19] webapp= path=/replication params={command=details&wt=javabin} status=0 QTime=24
Jul 30, 2010 9:13:05 AM org.apache.solr.handler.ReplicationHandler doFetch
SEVERE: SnapPull failed
java.util.ConcurrentModificationException
        at java.util.AbstractList$Itr.checkForComodification(AbstractList.java:372)
        at java.util.AbstractList$Itr.next(AbstractList.java:343)
        at java.util.AbstractCollection.addAll(AbstractCollection.java:305)
        at org.apache.lucene.index.SegmentInfos.files(SegmentInfos.java:826)
        at org.apache.lucene.index.DirectoryReader$ReaderCommit.<init>(DirectoryReader.java:916)
        at org.apache.lucene.index.DirectoryReader.getIndexCommit(DirectoryReader.java:856)
        at org.apache.solr.search.SolrIndexReader.getIndexCommit(SolrIndexReader.java:454)
        at org.apache.solr.handler.SnapPuller.fetchLatestIndex(SnapPuller.java:261)
        at org.apache.solr.handler.ReplicationHandler.doFetch(ReplicationHandler.java:264)
        at org.apache.solr.handler.ReplicationHandler$1.run(ReplicationHandler.java:146)
"
1,"EnglishPossessiveFilter should work with Unicode right single quotation mark. The current EnglishPossessiveFilter (used in EnglishAnalyzer) removes possessives using only the '\'' character (plus 's' or 'S'), but some common systems (German?) insert the Unicode ""\u2019"" (RIGHT SINGLE QUOTATION MARK) instead and this is not removed when processing UTF-8 text. I propose to change EnglishPossesiveFilter to support '\u2019' as an alternative to '\''."
1,"Bug in SegmentTermPositions if used for first term in the dictionary. When a SegmentTermPositions object is reset via seek() it does not move
the proxStream to the correct position in case the term is the first one
in the dictionary.

The reason for this behavior is that the skipStream is only moved if
lazySkipPointer is != 0. But 0 is a valid value for the posting list of
the very first term. The fix is easy: We simply have to set lazySkipPointer
to -1 in case no lazy skip has to be performed and then we only move the
skipStream if lazySkipPointer!=-1."
1,"NumericTokenStream.NumericTermAttribute does not support cloning -> Solr analysis request handlers fail. During converting Solr's AnalysisRequestHandlers (LUCENE-2374) I noticed, that the current implementation of NumericTokenStream fails on cloneAttributes(), which is needed to buffer the tokens for structured display.

This issue should fix this by refactoring the inner class."
1,Benchmark deletes.alg fails. Benchmark deletes.alg fails because the index reader defaults to open readonly.  
1,"Problem with IndexWriter.mergeFinish. I'm getting a (very) infrequent assert in IndexWriter.mergeFinish from TestIndexWriter.testAddIndexOnDiskFull. The problem occurs during the rollback when the merge hasn't been registered. I'm not 100% sure this is the correct fix, because it's such an infrequent event. 

{code:java}
  final synchronized void mergeFinish(MergePolicy.OneMerge merge) throws IOException {
    
    // Optimize, addIndexes or finishMerges may be waiting
    // on merges to finish.
    notifyAll();

    if (merge.increfDone)
      decrefMergeSegments(merge);

    assert merge.registerDone;

    final SegmentInfos sourceSegments = merge.segments;
    final int end = sourceSegments.size();
    for(int i=0;i<end;i++)
      mergingSegments.remove(sourceSegments.info(i));
    mergingSegments.remove(merge.info);
    merge.registerDone = false;
  }
{code}

Should  be something like:

{code:java}
  final synchronized void mergeFinish(MergePolicy.OneMerge merge) throws IOException {
    
    // Optimize, addIndexes or finishMerges may be waiting
    // on merges to finish.
    notifyAll();

    if (merge.increfDone)
      decrefMergeSegments(merge);

    if (merge.registerDone) {
      final SegmentInfos sourceSegments = merge.segments;
      final int end = sourceSegments.size();
      for(int i=0;i<end;i++)
        mergingSegments.remove(sourceSegments.info(i));
      mergingSegments.remove(merge.info);
      merge.registerDone = false;
    }
  }
{code}"
1,"ChunkedInputStream incorrectly handles chunksize without semicolon. ChunkedInputStream does not correctly read the chunk size when a semicolon does
not appear in the first line of the chunk.  If whitespace exists between the
chunk size value and the end of line and no semicolon is present, the whitespace
is not removed before parseInt is called resulting in an IOException ""Bad chunk
size""

I can not tell from RFC2616 if whitespace is legal here, but I have received it
from at least one web server.  The relevant section is 3.6.1.

A small patch repairs the problem.  I will attach it immediately."
1,"BlockJoinQuery doesn't implement boost. After reviewing LUCENE-3494, i checked other queries and noticed that BlockJoinQuery currently throws UOE for getBoost and setBoost:
{noformat}
throw new UnsupportedOperationException(""this query cannot support boosting; please use childQuery.setBoost instead"");
{noformat}

I don't think we can safely do that in queries, because other parts of lucene rely upon this working... for example BQs rewrite when
it has a single clause and erases itself.

So I think we should just pass down the boost to the inner weight.
"
1,"Memory leak in MultiThreadedHttpClient caused by bad .equals(). Note: I have '2.0 release candidate 1'; I'm not sure which version this
translates into.  The bug is definitely present in the current source.

MultiThreadedHttpClient uses the following code:

// Look for a list of connections for the given config
HostConnectionPool listConnections = (HostConnectionPool) 
    mapHosts.get(hostConfiguration);
if (listConnections == null) { 
    // First time for this config
    listConnections = new HostConnectionPool();
    listConnections.hostConfiguration = hostConfiguration;
    mapHosts.put(hostConfiguration, listConnections);
}


The hash map relys on HostConfiguration's .equals() to resolve equality &
determine if there is a mapping for the configuration.

HostConfiguration has the following in it's .equals() method:

if (!protocol.equals(config.getProtocol())) {
    return false;
}

. . . and Protocol has:

if (obj instanceof Protocol) {
            
    Protocol p = (Protocol) obj;
            
    return (
        defaultPort == p.getDefaultPort()
        && scheme.equalsIgnoreCase(p.getScheme())
        && secure == p.isSecure()
        && socketFactory.equals(p.getSocketFactory()));

}

However, there is no .equals() method in any of the ProtocolSocketFactory
objects, and there isn't any note in the interface about the necessity of the
.equals() method."
1,"Hop 0 sample app doesn't exit because of on-daemon thread pool-1-thread-1. When starting the sample app Hop 0 (or any other Hop sample app) if there is no ""repository"" directory, then the application doesn't exit because there is a non-daemon thread named ""pool-1-thread-1""."
1,"Fix unexpected behavior of Text.getName(). Text.getName() and variants does return an empty string, if the given path is already a name. eg:

Text.getName(""foo"") returns """" and not ""foo"" as one would expect for relative paths.
suggest to change this."
1,"unable to workspace import XML.. tika detects xml as ""application/xml"" thus breaking the org.apache.jackrabbit.server.io.XmlHandler
which just checks for ""text/xml""."
1,"Session.save() potentially causes endless loop when READ permission is denied on root node. if the current session doesn't have read permission on the root node, calling Session.save() triggers a call to SessionItemStateManager.getIdOfRootTransientNodeState()
in order to find the root of the minimal subtree including all transient states. this might cause an endless loop, depending on the transient changes."
1,"Item.remove fails if a child-item is not visible to the editing session. the following test setup fails:

- a given session is allowed to remove a node
- the node has a policy child node which is not visible to the editing session (missing ac-read permission)
  OR the node has another invisible child item which could - based on the permissions above - be removed by that session.

calling Node.remove however fails with accessdeniedexception because the internal remove
mechanism accesses all child items to mark them removed. however, the access is executed
using the regular itemmgr calls that are used to retrieve the items using the JCR API which
results in accessdenied exception as those child items are not visible to the session.
since the items can be removed i would argue that this is a bug in the internal remove process.
"
1,"Lucene Query Exception: 'attempt to access a deleted document'. Hi,

I am getting an exception when trying to execute a query through the (Spring) JcrTemplate class....using the following code:
QueryManager qMgr = session.getWorkspace().getQueryManager();
QueryResult result = qMgr.createQuery(xpathQuery, Query.XPATH ).execute();

The exception is thrown at the second line and is as follows:

[DEBUG] << ""[0x9]at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:113)[\n]""
[DEBUG] << ""[0x9]at org.apache.lucene.search.Hits.getMoreDocs(Hits.java:74)[\n]""
[DEBUG] << ""[0x9]at org.apache.lucene.search.Hits.&lt;init>(Hits.java:53)[\n]""
[DEBUG] << ""[0x9]at org.apache.lucene.search.Searcher.search(Searcher.java:46)[\n]""
[DEBUG] << ""[0x9]at org.apache.lucene.search.Searcher.search(Searcher.java:38)[\n]""
[DEBUG] << ""[0x9]at org.apache.jackrabbit.core.query.lucene.SearchIndex.executeQuery(SearchIndex.java:660)[\n]""
[DEBUG] << ""[0x9]at org.apache.jackrabbit.core.query.lucene.QueryResultImpl.executeQuery(QueryResultImpl.java:242)[\n]""
[DEBUG] << ""[0x9]at org.apache.jackrabbit.core.query.lucene.QueryResultImpl.getResults(QueryResultImpl.java:290)[\n]""
[DEBUG] << ""[0x9]at org.apache.jackrabbit.core.query.lucene.QueryResultImpl.&lt;init>(QueryResultImpl.java:192)[\n]""
[DEBUG] << ""[0x9]at org.apache.jackrabbit.core.query.lucene.QueryImpl.execute(QueryImpl.java:138)[\n]""
[DEBUG] << ""[0x9]at org.apache.jackrabbit.core.query.QueryImpl.execute(QueryImpl.java:176)[\n]""
[DEBUG] << ""[0x9]at com.intel.cds.cr.jcr.JcrManager$5.doInJcr(JcrManager.java:363)[\n]""
[DEBUG] << ""[0x9]at org.springmodules.jcr.JcrTemplate.execute(JcrTemplate.java:76)[\n]""
[DEBUG] << ""[0x9]at org.springmodules.jcr.JcrTemplate.execute(JcrTemplate.java:108)[\n]""
[DEBUG] << ""[0x9]... 19 more[\n]""
[DEBUG] << ""</Exception></detail></soapenv:Fault></soapenv:Body></soapenv:Envelope>""
org.apache.axis2.AxisFault: attempt to access a deleted document
	at org.apache.axis2.util.Utils.getInboundFaultFromMessageContext(Utils.java:486)
	at org.apache.axis2.description.OutInAxisOperationClient.handleResponse(OutInAxisOperation.java:343)
	at org.apache.axis2.description.OutInAxisOperationClient.send(OutInAxisOperation.java:389)
	at org.apache.axis2.description.OutInAxisOperationClient.executeImpl(OutInAxisOperation.java:211)
	at org.apache.axis2.client.OperationClient.execute(OperationClient.java:163)


My Jackrabbit/Lucene configuration is as follows:

<SearchIndex class=""org.apache.jackrabbit.core.query.lucene.SearchIndex"">
        <param name=""path"" value=""${rep.home}/repository/index""/>
        
        <param name=""useCompoundFile"" value=""false""/>
        <param name=""mergeFactor"" value=""5""/>
        <param name=""cacheSize"" value=""10000""/>
        <param name=""respectDocumentOrder"" value=""false""/>  
  </SearchIndex>

Is this a configuration issue or a bug?

Thanks,
David."
1,"IndexCommit.getFileNames() should not return dups. If the index was created with autoCommit false, and more than 1
segment was flushed during the IndexWriter session, then the shared
doc-store files are incorrectly duplicated in
IndexCommit.getFileNames().  This is because that method is walking
through each SegmentInfo, appending its files to a list.  Since
multiple SegmentInfo's may share the doc store files, this causes dups.

To fix this, I've added a SegmentInfos.files(...) method, and
refactored all places that were computing their files one SegmentInfo
at a time to use this new method instead.
"
1,"NodeTypeDefDiff compares to restrictive. The NodeTypeDefDiff class is used to compare NodeTypeDef instances. Unfortunately this class reports two NodeTypeDef instances which are not equal but have no structural difference as having trivial changes. The correct result would be to have no modification at all.

I suggest to modify the NodeTypeDefDiff.init() method such, that the initial type is ""NONE"" instead of ""TRIVIAL"" and to first compare the ""hasOrderableChildNodes"" first and raise the level to ""TRIVIAL"" if not equal. Next the rest of the current comparisons would follow."
1,Tika configuration may use wrong class loader. The configurable Tika parser construction mechanism added in JCR-2864 constructs the parser instance lazily when the first indexing request is made. This may confuse things as the context class loader used by Tika to load all the available parser classes may not always be the class loader used to create the repository. To avoid this problem the Tika parser should be constructed already during normal repository initialization.
1,"memory leak in MultiThreadedHttpConnectionManager. MultiThreadedHttpConnectionManager.getConnectionsInPool(hostConfiguration) will create HostConnectionPool entries that will not be cleaned up unless they are later used for communication. This should be changed to not create pools in that method, but rather return 0 for a non-existent pool.
"
1,"DocViewSAXEventGenerator produces invalid SAX stream. ISO9075.encode() is called twice in DocViewSAXEventGenerator.leaving(), which produces invalid endElement events.

Faulty block of code (note the encode method called twice):

        // encode node name to make sure it's a valid xml name
        name = ISO9075.encode(name);
        // element name
        String elemName;
        if (node.getDepth() == 0) {
            // root node needs a name
            elemName = jcrRoot;
        } else {
            // encode node name to make sure it's a valid xml name
            elemName = ISO9075.encode(name);
        }"
1,"Missing Content-Length header makes cached entry invalid. A cached entry whose original response didn't carry a Content-Length header, should not be rejected for considered invalid because the length of its cached content is different from the non-existing Content-Length header value. The attached patch only verifies the lengths if the header was originally present."
1,AbstractExcerpt uses wrong logger. It uses DefaultXMLExcerpt instead of AbstractExcerpt.
1,"derelativizing of relative URIs with a scheme is incorrect. URI constructor ""public URI(URI base, URI relative) throws URIException"" assumes that if given 'relative' URI has a scheme, it should provide an authority and complete path to the constructed URI. However, a URI can have a scheme but still be relative, requiring the authority and base path of the 'base' URI. 

Demonstration code:

URI base = new URI(""http://www.example.com/some/page"");
URI rel = new URI(""http:boo"");
URI derel = new URI(base,rel);
derel.toString();
(java.lang.String) http:boo

In fact, derel should be ""http://www.example.com/some/boo"". 

RFC2396 is a little confused about this; section 3.1 states """"Relative URI references are distinguished from absolute URI in that they do not begin with a scheme name."" But, in section 5, there are several sentences talking about relative URIs that begin with schemes (and how this prevents using relative URIs that have leading path segments that look like scheme identifiers). 

RFC3896, which supercedes RFC2396, removes the implication a relative URI cannot begin with a scheme, leaving the other text explcitly discussing relative URIs with schemes. 

Both Firefox (1.5) and IE (6.0) treat ""http:boo"" the same as ""boo"" for purposes of derelativization against an HTTP base URI, which would give the final URI ""http://www.example.com/some/boo"" in the example above. 

Even relative URIs like ""http:../../boo"" are explicitly legal. 

"
1,"Unmatched right parentheses truncates query. The query processor truncates a query when right parentheses are unmatched.
E.g.:

 secret AND illegal) AND access:confidential

will not result in a ParseException instead will run as:

 secret AND illegal"
1,"Registering node type names with spaces fails in clustered environment. Registering a node type name that contains at least one space in a clustered environment will cause a JournalException in cluster nodes trying to read that change back from the journal. The stack trace observed is:

JournalException: Parse error while reading node type definition.
       at AbstractRecord.readNodeTypeDef(AbstractRecord.java:245)
       ...
Caused by: ParseException: Missing '[' delimiter for beginning of node type name ((internal), line 47)
       at Lexer.fail(Lexer.java:148)
       ...

(package names and intermediate frames omitted for brevity)."
1,"inconsistent repository after overlapping node add operations. It seems I can reproduce a sequence of operations that cause the repository to be inconsistent.

The short version: 2 sessions add a same-named child node to the same parent folder (not allowing same-name-siblings). Session 1's save() succeeds. Session 2's save() fails, but succeeds on retry (!).

After the operation, the child node created by session 1 is still present, but the parent doesn't list it as child node anymore.

(will add test case)"
1,"BasicCookieStore.getCookies() returns non-threadsafe collection. BasicCookieStore.getCookies() is a simple method.  It's synchronized, and it returns an unmodifiable wrapper around the underlying cookie list.  If the caller were to then iterate over it as another thread were to manipulate the cookie list via BasicCookieStore, this would create a thread un-safe situation because both threads aren't doing their reading/writing with the same lock (the reader doesn't even have a lock).

I suggest fixing this by using CopyOnWriteArrayList, or by making a defensive copy in getCookies()

This issue might apply to some of the other basic implementations of some of the interfaces but I haven't checked."
1,"DirectIOLinuxDirectory hardwires buffer size and creates files with invalid permissions. TestDemo fails if I use the DirectIOLinuxDirectory (using Robert's new -Dtests.directory=XXX), because when it O_CREATs a file, it fails to specify the mode, so [depending on C stack!] you can get permission denied.

Also, we currently hardwire the buffer size to 1 MB (Mark found this)... I plan to add a ""forcedBufferSize"" to the DirectIOLinuxDir's ctor, to optionally override lucene's default buffer sizes (which are way too small for direct IO to get barely OK performance).  If you pass 0 for this then you get Lucene's default buffer sizes..."
1,"Proxy NTLM Authentication  Redirecting to different address fails saying Proxy Auth Required.. The issue has been discussed in,
http://www.nabble.com/redirect-fails-when-NTLM-authentication-is-used-for-proxy-tt23867531.html

This was found in http client 3.1 release,  where NTLM proxy authentication is must and the server ask the redirect to a new url, in this case, when redirecting, the earlier proxy auth status is not cleared, so, it does not do proxy authentication for the new URL and hence fails.

Target Host Authenticaiton NTLM authentication - redirect also had problem and fixed as said,
http://issues.apache.org/jira/browse/HTTPCLIENT-211
Proxy Authentication - redirect has to be fixed, 

The wire logs for the release https://repository.apache.org/content/repositories/snapshots/org/apache/httpcomponents/httpclient/4.0-beta3-SNAPSHOT/
is given below,

[DEBUG] wire - >> ""GET http://verisign.com HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Negotiate[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Kerberos[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: NTLM[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Basic realm=""lab1.""[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Pragma: no-cache[EOL]""
[DEBUG] wire - << ""Cache-Control: no-cache[EOL]""
[DEBUG] wire - << ""Content-Type: text/html[EOL]""
[DEBUG] wire - << ""Content-Length: 4107  [EOL]""
[DEBUG] wire - << ""[EOL]""
[DEBUG] wire - << ""<!DOCTYPE HTML PUBLIC ""-//W3C//DTD HTML 4.0 Transitional//EN"">[\r][\n]""
[DEBUG] wire - << ""<HTML><HEAD><TITLE>Error Message</TITLE>[\r][\n]""
[DEBUG] wire - << ""<META http-equiv=Content-Type content=""text/html; charset=UTF-8"">[\r][\n]""
[DEBUG] wire - << ""<STYLE id=L_default_1>A {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: bold; FONT-SIZE: 10pt; COLOR: #005a80; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""A:hover {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: bold; FONT-SIZE: 10pt; COLOR: #0d3372; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""TD {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-SIZE: 8pt; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""TD.titleBorder {[\r][\n]""
[DEBUG] wire - << ""[0x9]BORDER-RIGHT: #955319 1px solid; BORDER-TOP: #955319 1px solid; PADDING-LEFT: 8px; FONT-WEIGHT: bold; FONT-SIZE: 12pt; VERTICAL-ALIGN: middle; BORDER-LEFT: #955319 0px solid; COLOR: #955319; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: tahoma; HEIGHT: 35px; BACKGROUND-COLOR: #d2b87a; TEXT-ALIGN: left[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""TD.titleBorder_x {[\r][\n]""
[DEBUG] wire - << ""[0x9]BORDER-RIGHT: #955319 0px solid; BORDER-TOP: #955319 1px solid; PADDING-LEFT: 8px; FONT-WEIGHT: bold; FONT-SIZE: 12pt; VERTICAL-ALIGN: middle; BORDER-LEFT: #955319 1px solid; COLOR: #978c79; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: tahoma; HEIGHT: 35px; BACKGROUND-COLOR: #d2b87a; TEXT-ALIGN: left[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".TitleDescription {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: bold; FONT-SIZE: 12pt; COLOR: black; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""SPAN.explain {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: normal; FONT-SIZE: 10pt; COLOR: #934225[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""SPAN.TryThings {[\r][\n]""
[DEBUG] wire - << ""[0x9]FONT-WEIGHT: normal; FONT-SIZE: 10pt; COLOR: #934225[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".TryList {[\r][\n]""
[DEBUG] wire - << ""[0x9]MARGIN-TOP: 5px; FONT-WEIGHT: normal; FONT-SIZE: 8pt; COLOR: black; FONT-FAMILY: tahoma[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".X {[\r][\n]""
[DEBUG] wire - << ""[0x9]BORDER-RIGHT: #955319 1px solid; BORDER-TOP: #955319 1px solid; FONT-WEIGHT: normal; FONT-SIZE: 12pt; BORDER-LEFT: #955319 1px solid; COLOR: #7b3807; BORDER-BOTTOM: #955319 1px solid; FONT-FAMILY: verdana; BACKGROUND-COLOR: #d1c2b4[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << "".adminList {[\r][\n]""
[DEBUG] wire - << ""[0x9]MARGIN-TOP: 2px[\r][\n]""
[DEBUG] wire - << ""}[\r][\n]""
[DEBUG] wire - << ""</STYLE>[\r][\n]""
[DEBUG] wire - << ""<META content=""MSHTML 6.00.2800.1170"" name=GENERATOR></HEAD>[\r][\n]""
[DEBUG] wire - << ""<BODY bgColor=#f3f3ed>[\r][\n]""
[DEBUG] wire - << ""<TABLE cellSpacing=0 cellPadding=0 width=""100%"">[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD class=titleborder_x width=30>[\r][\n]""
[DEBUG] wire - << ""      <TABLE height=25 cellSpacing=2 cellPadding=0 width=25 bgColor=black>[\r][\n]""
[DEBUG] wire - << ""        <TBODY>[\r][\n]""
[DEBUG] wire - << ""        <TR>[\r][\n]""
[DEBUG] wire - << ""          <TD class=x vAlign=center alig""
[DEBUG] wire - << ""n=middle>X</TD>[\r][\n]""
[DEBUG] wire - << ""        </TR>[\r][\n]""
[DEBUG] wire - << ""        </TBODY>[\r][\n]""
[DEBUG] wire - << ""      </TABLE>[\r][\n]""
[DEBUG] wire - << ""    </TD>[\r][\n]""
[DEBUG] wire - << ""    <TD class=titleBorder id=L_default_2>Network Access Message:<SPAN class=TitleDescription> The page cannot be displayed</SPAN> </TD>[\r][\n]""
[DEBUG] wire - << ""  </TR>[\r][\n]""
[DEBUG] wire - << ""  </TBODY>[\r][\n]""
[DEBUG] wire - << ""</TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""<TABLE id=spacer>[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD height=10></TD></TR></TBODY></TABLE>[\r][\n]""
[DEBUG] wire - << ""<TABLE width=400>[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD noWrap width=25></TD>[\r][\n]""
[DEBUG] wire - << ""    <TD width=400><SPAN class=explain><ID id=L_default_3><B>Explanation:</B></ID></SPAN><ID id=L_default_4> There is a problem with the page you are trying to reach and it cannot be displayed. </ID><BR><BR>[\r][\n]""
[DEBUG] wire - << ""    <B><SPAN class=tryThings><ID id=L_default_5><B>Try the following:</B></ID></SPAN></B> [\r][\n]""
[DEBUG] wire - << ""      <UL class=TryList>[\r][\n]""
[DEBUG] wire - << ""        <LI id=L_default_6><B>Refresh page:</B> Search for the page again by clicking the Refresh button. The timeout may have occurred due to Internet congestion.[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_7><B>Check spelling:</B> Check that you typed the Web page address correctly. The address may have been mistyped.[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_8><B>Access from a link:</B> If there is a link to the page you are looking for, try accessing the page from that link.[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""      </UL>[\r][\n]""
[DEBUG] wire - << ""<ID id=L_default_9>If you are still not able to view the requested page, try contacting your administrator or Helpdesk.</ID> <BR><BR>[\r][\n]""
[DEBUG] wire - << ""    </TD>[\r][\n]""
[DEBUG] wire - << ""  </TR>[\r][\n]""
[DEBUG] wire - << ""  </TBODY>[\r][\n]""
[DEBUG] wire - << ""</TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""<TABLE id=spacer><TBODY><TR><TD height=15></TD></TR></TBODY></TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""<TABLE width=400>[\r][\n]""
[DEBUG] wire - << ""  <TBODY>[\r][\n]""
[DEBUG] wire - << ""  <TR>[\r][\n]""
[DEBUG] wire - << ""    <TD noWrap width=25></TD>[\r][\n]""
[DEBUG] wire - << ""    <TD width=400 id=L_default_10><B>Technical Information (for support personnel)</B> [\r][\n]""
[DEBUG] wire - << ""      <UL class=adminList>[\r][\n]""
[DEBUG] wire - << ""        <LI id=L_default_11>Error Code: 407 Proxy Authentication Required. The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied. (12209)[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_12>IP Address: x.x.x.x[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_13>Date: 6/29/2009 11:15:15 AM [GMT][\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_14>Server: lab1[\r][\n]""
[DEBUG] wire - << ""<LI id=L_default_15>Source: proxy[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""      </UL>[\r][\n]""
[DEBUG] wire - << ""    </TD>[\r][\n]""
[DEBUG] wire - << ""  </TR>[\r][\n]""
[DEBUG] wire - << ""  </TBODY>[\r][\n]""
[DEBUG] wire - << ""</TABLE>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - << ""</BODY>[\r][\n]""
[DEBUG] wire - << ""</HTML>[\r][\n]""
[DEBUG] wire - << ""[\r][\n]""
[DEBUG] wire - >> ""GET http://verisign.com HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""Proxy-Authorization: NTLM TlRMTVNTUAABAAAAATIAAAgACAAgAAAADgAOACgAAABNWURPTUFJTkpDSUZTMjMwXzg2Xzkx[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 407 Proxy Authentication Required ( Access is denied.  )[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: NTLM TlRMTVNTUAACAAAAAAAAADgAAAABAgACqbXrIWnZ3i4AAAAAAAAAAAAAAAA4AAAABQLODgAAAA8=[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Pragma: no-cache[EOL]""
[DEBUG] wire - << ""Cache-Control: no-cache[EOL]""
[DEBUG] wire - << ""Content-Type: text/html[EOL]""
[DEBUG] wire - << ""Content-Length: 0     [EOL]""
[DEBUG] wire - << ""[EOL]""
[DEBUG] wire - >> ""GET http://verisign.com HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""Proxy-Authorization: NTLM TlRMTVNTUAADAAAAGAAYAEAAAAAwADAAWAAAABAAEACIAAAAGgAaAJgAAAAcABwAsgAAAAAAAAAAAAAAAQIAAAXLpW40q7jqh7E6FgFnJqy9529ANaSLqfTiwjyF2BrUP9F8ObYOyYsBAQAAAAAAACDgxRg9+skBRt4mUOFFCs0AAAAAAAAAAE0AWQBEAE8ATQBBAEkATgBBAGQAbQBpAG4AaQBzAHQAcgBhAHQAbwByAEoAQwBJAEYAUwAyADMAMABfADgANgBfADkAMQA=[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 301 Unknown reason[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Content-length: 0[EOL]""
[DEBUG] wire - << ""Date: Mon, 29 Jun 2009 11:16:50 GMT[EOL]""
[DEBUG] wire - << ""Location: http://www.verisign.com/[EOL]""
[DEBUG] wire - << ""Content-type: text/html[EOL]""
[DEBUG] wire - << ""Server: Netscape-Enterprise/4.1[EOL]""
[DEBUG] wire - << ""[EOL]""
[ERROR] RequestProxyAuthentication - Proxy authentication error: Unexpected state: MSG_TYPE3_GENERATED
[DEBUG] wire - >> ""GET http://www.verisign.com/ HTTP/1.1[EOL]""
[DEBUG] wire - >> ""Host: www.verisign.com[EOL]""
[DEBUG] wire - >> ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - >> ""User-Agent: Apache-HttpClient/UNAVAILABLE (java 1.5)[EOL]""
[DEBUG] wire - >> ""[EOL]""
[DEBUG] wire - << ""HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )[EOL]""
[DEBUG] wire - << ""Via: 1.1 lab1[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Negotiate[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Kerberos[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: NTLM[EOL]""
[DEBUG] wire - << ""Proxy-Authenticate: Basic realm=""lab1.""[EOL]""
[DEBUG] wire - << ""Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Proxy-Connection: Keep-Alive[EOL]""
[DEBUG] wire - << ""Pragma: no-cache[EOL]""
[DEBUG] wire - << ""Cache-Control: no-cache[EOL]""
[DEBUG] wire - << ""Content-Type: text/html[EOL]""
[DEBUG] wire - << ""Content-Length: 4107  [EOL]""
[DEBUG] wire - << ""[EOL]""
----------------------------------------
HTTP/1.1 407 Proxy Authentication Required ( The ISA Server requires authorization to fulfill the request. Access to the Web Proxy filter is denied.  )

Thanks,
Raj





"
1,"MatchAllDocsQueryNode toString() creates invalid XML-Tag. MatchAllDocsQueryNode.toString() returns ""<matchAllDocs field='*' term='*'>"", which is inavlid XML should read ""<matchAllDocs field='*' term='*' />.
"
1,"TransientRepository does not shutdown if first login fails. The TransientRepository.login() method initializes the underlying repository when it is first called (initially or after the repository has previously been shut down) bug doesn't shut down the initialized repository if the login fails. If the application then decides to exit or otherwise not start another session, then the repository remains in an initialized state with no active sessions.

This issue should be fixed by properly handling login failures in the TransientRepository.login() method."
1,"TestIndexWriter.testCommitThreadSafety fails on realtime_search branch. Hudson failed on RT with this error - I wasn't able to reproduce yet....

{noformat}
NOTE: reproduce with: ant test -Dtestcase=TestIndexWriter -Dtestmethod=testCommitThreadSafety -Dtests.seed=410261592077577885:-4099127561715488589 -Dtests.multiplier=3
NOTE: reproduce with: ant test -Dtestcase=TestIndexWriter -Dtestmethod=testCommitThreadSafety -Dtests.seed=410261592077577885:-4099127561715488589 -Dtests.multiplier=3
The following exceptions were thrown by threads:
*** Thread: Thread-331 ***
java.lang.RuntimeException: java.lang.AssertionError: term=f:2_0; r=DirectoryReader(segments_6 _8(4.0):Cv7) expected:<1> but was:<0>
	at org.apache.lucene.index.TestIndexWriter$5.run(TestIndexWriter.java:2416)
Caused by: java.lang.AssertionError: term=f:2_0; r=DirectoryReader(segments_6 _8(4.0):Cv7) expected:<1> but was:<0>
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:126)
	at org.junit.Assert.assertEquals(Assert.java:470)
	at org.apache.lucene.index.TestIndexWriter$5.run(TestIndexWriter.java:2410)
NOTE: test params are: codec=RandomCodecProvider: {=SimpleText, f6=MockVariableIntBlock(baseBlockSize=91), f7=MockFixedIntBlock(blockSize=1289), f8=Standard, f9=MockRandom, f1=MockSep, f0=Pulsing(freqCutoff=15), f3=Pulsing(freqCutoff=15), f2=MockFixedIntBlock(blockSize=1289), f5=MockVariableIntBlock(baseBlockSize=91), f4=MockRandom, f=MockSep, c=MockVariableIntBlock(baseBlockSize=91), termVector=SimpleText, d9=SimpleText, d8=MockSep, d5=MockVariableIntBlock(baseBlockSize=91), d4=MockRandom, d7=Standard, d6=SimpleText, d25=Standard, d0=MockVariableIntBlock(baseBlockSize=91), c29=Standard, d24=SimpleText, d1=MockFixedIntBlock(blockSize=1289), c28=MockFixedIntBlock(blockSize=1289), d23=MockVariableIntBlock(baseBlockSize=91), d2=Standard, c27=MockVariableIntBlock(baseBlockSize=91), d22=MockRandom, d3=MockRandom, d21=MockFixedIntBlock(blockSize=1289), d20=MockVariableIntBlock(baseBlockSize=91), c22=MockVariableIntBlock(baseBlockSize=91), c21=MockRandom, c20=Pulsing(freqCutoff=15), d29=MockVariableIntBlock(baseBlockSize=91), c26=SimpleText, d28=MockRandom, c25=MockSep, d27=Pulsing(freqCutoff=15), c24=MockRandom, d26=MockFixedIntBlock(blockSize=1289), c23=Standard, e9=MockRandom, e8=MockFixedIntBlock(blockSize=1289), e7=MockVariableIntBlock(baseBlockSize=91), e6=MockSep, e5=Pulsing(freqCutoff=15), c17=Standard, e3=MockFixedIntBlock(blockSize=1289), d12=SimpleText, c16=SimpleText, e4=Pulsing(freqCutoff=15), d11=MockSep, c19=MockSep, e1=MockSep, d14=Pulsing(freqCutoff=15), c18=Pulsing(freqCutoff=15), e2=SimpleText, d13=MockFixedIntBlock(blockSize=1289), e0=Standard, d10=Standard, d19=Pulsing(freqCutoff=15), c11=SimpleText, c10=MockSep, d16=MockRandom, c13=MockSep, c12=Pulsing(freqCutoff=15), d15=Standard, d18=SimpleText, c15=MockFixedIntBlock(blockSize=1289), d17=MockSep, c14=MockVariableIntBlock(baseBlockSize=91), b3=MockRandom, b2=Standard, b5=SimpleText, b4=MockSep, b7=MockSep, b6=Pulsing(freqCutoff=15), d50=MockVariableIntBlock(baseBlockSize=91), b9=MockFixedIntBlock(blockSize=1289), b8=MockVariableIntBlock(baseBlockSize=91), d43=Pulsing(freqCutoff=15), d42=MockFixedIntBlock(blockSize=1289), d41=SimpleText, d40=MockSep, d47=MockRandom, d46=Standard, b0=SimpleText, d45=MockFixedIntBlock(blockSize=1289), b1=Standard, d44=MockVariableIntBlock(baseBlockSize=91), d49=MockSep, d48=Pulsing(freqCutoff=15), c6=MockVariableIntBlock(baseBlockSize=91), c5=MockRandom, c4=Pulsing(freqCutoff=15), c3=MockFixedIntBlock(blockSize=1289), c9=MockSep, c8=MockRandom, c7=Standard, d30=MockFixedIntBlock(blockSize=1289), d32=MockRandom, d31=Standard, c1=MockVariableIntBlock(baseBlockSize=91), d34=Standard, c2=MockFixedIntBlock(blockSize=1289), d33=SimpleText, d36=MockSep, c0=MockSep, d35=Pulsing(freqCutoff=15), d38=MockVariableIntBlock(baseBlockSize=91), d37=MockRandom, d39=SimpleText, e92=MockFixedIntBlock(blockSize=1289), e93=Pulsing(freqCutoff=15), e90=MockSep, e91=SimpleText, e89=MockVariableIntBlock(baseBlockSize=91), e88=MockSep, e87=Pulsing(freqCutoff=15), e86=SimpleText, e85=MockSep, e84=MockRandom, e83=Standard, e80=MockFixedIntBlock(blockSize=1289), e81=Standard, e82=MockRandom, e77=MockVariableIntBlock(baseBlockSize=91), e76=MockRandom, e79=Standard, e78=SimpleText, e73=MockSep, e72=Pulsing(freqCutoff=15), e75=MockFixedIntBlock(blockSize=1289), e74=MockVariableIntBlock(baseBlockSize=91), binary=MockVariableIntBlock(baseBlockSize=91), f98=Pulsing(freqCutoff=15), f97=MockFixedIntBlock(blockSize=1289), f99=MockRandom, f94=Standard, f93=SimpleText, f96=MockSep, f95=Pulsing(freqCutoff=15), e95=SimpleText, e94=MockSep, e97=Pulsing(freqCutoff=15), e96=MockFixedIntBlock(blockSize=1289), e99=MockFixedIntBlock(blockSize=1289), e98=MockVariableIntBlock(baseBlockSize=91), id=MockRandom, f34=Standard, f33=SimpleText, f32=MockVariableIntBlock(baseBlockSize=91), f31=MockRandom, f30=MockFixedIntBlock(blockSize=1289), f39=Standard, f38=MockVariableIntBlock(baseBlockSize=91), f37=MockRandom, f36=Pulsing(freqCutoff=15), f35=MockFixedIntBlock(blockSize=1289), f43=MockSep, f42=Pulsing(freqCutoff=15), f45=MockFixedIntBlock(blockSize=1289), f44=MockVariableIntBlock(baseBlockSize=91), f41=SimpleText, f40=MockSep, f47=Standard, f46=SimpleText, f49=MockSep, f48=Pulsing(freqCutoff=15), content=MockSep, e19=SimpleText, e18=MockSep, e17=Standard, f12=SimpleText, e16=SimpleText, f11=MockSep, f10=MockRandom, e15=MockVariableIntBlock(baseBlockSize=91), e14=MockRandom, f16=MockRandom, e13=MockSep, f15=Standard, e12=Pulsing(freqCutoff=15), e11=Standard, f14=MockFixedIntBlock(blockSize=1289), e10=SimpleText, f13=MockVariableIntBlock(baseBlockSize=91), f19=Pulsing(freqCutoff=15), f18=Standard, f17=SimpleText, e29=MockRandom, e26=MockSep, f21=Pulsing(freqCutoff=15), e25=Pulsing(freqCutoff=15), f20=MockFixedIntBlock(blockSize=1289), e28=MockFixedIntBlock(blockSize=1289), f23=MockVariableIntBlock(baseBlockSize=91), e27=MockVariableIntBlock(baseBlockSize=91), f22=MockRandom, f25=SimpleText, e22=MockFixedIntBlock(blockSize=1289), f24=MockSep, e21=MockVariableIntBlock(baseBlockSize=91), f27=Pulsing(freqCutoff=15), e24=MockRandom, f26=MockFixedIntBlock(blockSize=1289), e23=Standard, f29=MockFixedIntBlock(blockSize=1289), f28=MockVariableIntBlock(baseBlockSize=91), e20=Pulsing(freqCutoff=15), field=MockRandom, string=Standard, e30=MockRandom, e31=MockVariableIntBlock(baseBlockSize=91), a98=Standard, e34=MockSep, a99=MockRandom, e35=SimpleText, f79=MockSep, e32=Standard, e33=MockRandom, b97=MockRandom, f77=MockRandom, e38=Standard, b98=MockVariableIntBlock(baseBlockSize=91), f78=MockVariableIntBlock(baseBlockSize=91), e39=MockRandom, b99=SimpleText, f75=MockFixedIntBlock(blockSize=1289), e36=MockVariableIntBlock(baseBlockSize=91), f76=Pulsing(freqCutoff=15), e37=MockFixedIntBlock(blockSize=1289), f73=Pulsing(freqCutoff=15), f74=MockSep, f71=SimpleText, f72=Standard, f81=MockFixedIntBlock(blockSize=1289), f80=MockVariableIntBlock(baseBlockSize=91), e40=Standard, e41=Pulsing(freqCutoff=15), e42=MockSep, e43=MockFixedIntBlock(blockSize=1289), e44=Pulsing(freqCutoff=15), e45=MockRandom, e46=MockVariableIntBlock(baseBlockSize=91), f86=SimpleText, e47=MockSep, f87=Standard, e48=SimpleText, f88=Pulsing(freqCutoff=15), e49=MockFixedIntBlock(blockSize=1289), f89=MockSep, f82=MockVariableIntBlock(baseBlockSize=91), f83=MockFixedIntBlock(blockSize=1289), f84=Standard, f85=MockRandom, f90=MockRandom, f92=SimpleText, f91=MockSep, str=MockSep, a76=SimpleText, e56=SimpleText, f59=MockVariableIntBlock(baseBlockSize=91), a77=Standard, e57=Standard, a78=Pulsing(freqCutoff=15), e54=MockRandom, f57=Pulsing(freqCutoff=15), a79=MockSep, e55=MockVariableIntBlock(baseBlockSize=91), f58=MockSep, e52=MockVariableIntBlock(baseBlockSize=91), e53=MockFixedIntBlock(blockSize=1289), e50=Pulsing(freqCutoff=15), e51=MockSep, f51=MockFixedIntBlock(blockSize=1289), f52=Pulsing(freqCutoff=15), f50=SimpleText, f55=Standard, f56=MockRandom, f53=MockVariableIntBlock(baseBlockSize=91), e58=MockFixedIntBlock(blockSize=1289), f54=MockFixedIntBlock(blockSize=1289), e59=Pulsing(freqCutoff=15), a80=MockRandom, e60=MockRandom, a82=SimpleText, a81=MockSep, a84=MockSep, a83=Pulsing(freqCutoff=15), a86=MockFixedIntBlock(blockSize=1289), a85=MockVariableIntBlock(baseBlockSize=91), a89=Standard, f68=Standard, e65=Pulsing(freqCutoff=15), f69=MockRandom, e66=MockSep, a87=MockVariableIntBlock(baseBlockSize=91), e67=MockVariableIntBlock(baseBlockSize=91), a88=MockFixedIntBlock(blockSize=1289), e68=MockFixedIntBlock(blockSize=1289), e61=Standard, e62=MockRandom, e63=MockSep, e64=SimpleText, f60=MockRandom, f61=MockVariableIntBlock(baseBlockSize=91), f62=SimpleText, f63=Standard, e69=SimpleText, f64=MockSep, f65=SimpleText, f66=MockFixedIntBlock(blockSize=1289), f67=Pulsing(freqCutoff=15), f70=MockSep, a93=MockVariableIntBlock(baseBlockSize=91), a92=MockRandom, a91=Pulsing(freqCutoff=15), e71=Pulsing(freqCutoff=15), a90=MockFixedIntBlock(blockSize=1289), e70=MockFixedIntBlock(blockSize=1289), a97=SimpleText, a96=MockSep, a95=MockRandom, a94=Standard, c58=MockFixedIntBlock(blockSize=1289), a63=MockVariableIntBlock(baseBlockSize=91), a64=MockFixedIntBlock(blockSize=1289), c59=Pulsing(freqCutoff=15), c56=MockSep, d59=MockRandom, a61=Pulsing(freqCutoff=15), c57=SimpleText, a62=MockSep, c54=SimpleText, c55=Standard, a60=SimpleText, c52=MockRandom, c53=MockVariableIntBlock(baseBlockSize=91), d53=Standard, d54=MockRandom, d51=MockVariableIntBlock(baseBlockSize=91), d52=MockFixedIntBlock(blockSize=1289), d57=Pulsing(freqCutoff=15), b62=MockFixedIntBlock(blockSize=1289), d58=MockSep, b63=Pulsing(freqCutoff=15), d55=SimpleText, b60=MockSep, d56=Standard, b61=SimpleText, b56=SimpleText, b55=MockSep, b54=MockRandom, b53=Standard, d61=SimpleText, b59=MockVariableIntBlock(baseBlockSize=91), d60=MockSep, b58=MockSep, b57=Pulsing(freqCutoff=15), c62=MockSep, c61=Pulsing(freqCutoff=15), a59=Pulsing(freqCutoff=15), c60=Standard, a58=MockFixedIntBlock(blockSize=1289), a57=MockSep, a56=Pulsing(freqCutoff=15), a55=Standard, a54=SimpleText, a72=Standard, c67=MockRandom, a73=MockRandom, c68=MockVariableIntBlock(baseBlockSize=91), a74=MockSep, c69=SimpleText, a75=SimpleText, c63=Pulsing(freqCutoff=15), c64=MockSep, a70=MockRandom, c65=MockVariableIntBlock(baseBlockSize=91), a71=MockVariableIntBlock(baseBlockSize=91), c66=MockFixedIntBlock(blockSize=1289), d62=MockSep, d63=SimpleText, d64=MockFixedIntBlock(blockSize=1289), b70=MockFixedIntBlock(blockSize=1289), d65=Pulsing(freqCutoff=15), b71=MockRandom, d66=MockVariableIntBlock(baseBlockSize=91), b72=MockVariableIntBlock(baseBlockSize=91), d67=MockFixedIntBlock(blockSize=1289), b73=SimpleText, d68=Standard, b74=Standard, d69=MockRandom, b65=Pulsing(freqCutoff=15), b64=MockFixedIntBlock(blockSize=1289), b67=MockVariableIntBlock(baseBlockSize=91), b66=MockRandom, d70=Pulsing(freqCutoff=15), b69=MockRandom, b68=Standard, d72=MockVariableIntBlock(baseBlockSize=91), d71=MockRandom, c71=MockFixedIntBlock(blockSize=1289), c70=MockVariableIntBlock(baseBlockSize=91), a69=SimpleText, c73=MockRandom, c72=Standard, a66=MockFixedIntBlock(blockSize=1289), a65=MockVariableIntBlock(baseBlockSize=91), a68=MockRandom, a67=Standard, c32=MockSep, c33=SimpleText, c30=Standard, c31=MockRandom, c36=MockVariableIntBlock(baseBlockSize=91), a41=MockRandom, c37=MockFixedIntBlock(blockSize=1289), a42=MockVariableIntBlock(baseBlockSize=91), a0=SimpleText, c34=Pulsing(freqCutoff=15), c35=MockSep, a40=Pulsing(freqCutoff=15), b84=Pulsing(freqCutoff=15), d79=MockSep, b85=MockSep, b82=SimpleText, d77=Standard, c38=SimpleText, b83=Standard, d78=MockRandom, c39=Standard, b80=Standard, d75=MockRandom, b81=MockRandom, d76=MockVariableIntBlock(baseBlockSize=91), d73=MockFixedIntBlock(blockSize=1289), d74=Pulsing(freqCutoff=15), d83=Standard, a9=MockSep, d82=SimpleText, d81=MockVariableIntBlock(baseBlockSize=91), d80=MockRandom, b79=MockSep, b78=Standard, b77=SimpleText, b76=MockVariableIntBlock(baseBlockSize=91), b75=MockRandom, a1=SimpleText, a35=Pulsing(freqCutoff=15), a2=Standard, a34=MockFixedIntBlock(blockSize=1289), a3=Pulsing(freqCutoff=15), a33=SimpleText, a4=MockSep, a32=MockSep, a5=MockFixedIntBlock(blockSize=1289), a39=MockRandom, c40=Pulsing(freqCutoff=15), a6=Pulsing(freqCutoff=15), a38=Standard, a7=MockRandom, a37=MockFixedIntBlock(blockSize=1289), a8=MockVariableIntBlock(baseBlockSize=91), a36=MockVariableIntBlock(baseBlockSize=91), c41=MockFixedIntBlock(blockSize=1289), c42=Pulsing(freqCutoff=15), c43=MockRandom, c44=MockVariableIntBlock(baseBlockSize=91), c45=Standard, a50=SimpleText, c46=MockRandom, a51=Standard, c47=MockSep, a52=Pulsing(freqCutoff=15), c48=SimpleText, a53=MockSep, b93=MockVariableIntBlock(baseBlockSize=91), d88=MockFixedIntBlock(blockSize=1289), c49=MockVariableIntBlock(baseBlockSize=91), b94=MockFixedIntBlock(blockSize=1289), d89=Pulsing(freqCutoff=15), b95=Standard, b96=MockRandom, d84=SimpleText, b90=SimpleText, d85=Standard, b91=MockFixedIntBlock(blockSize=1289), d86=Pulsing(freqCutoff=15), b92=Pulsing(freqCutoff=15), d87=MockSep, d92=MockSep, d91=Pulsing(freqCutoff=15), d94=MockFixedIntBlock(blockSize=1289), d93=MockVariableIntBlock(baseBlockSize=91), b87=MockSep, b86=Pulsing(freqCutoff=15), d90=SimpleText, b89=MockFixedIntBlock(blockSize=1289), b88=MockVariableIntBlock(baseBlockSize=91), a44=MockVariableIntBlock(baseBlockSize=91), a43=MockRandom, a46=Standard, a45=SimpleText, a48=SimpleText, a47=MockSep, c51=Standard, a49=MockFixedIntBlock(blockSize=1289), c50=SimpleText, d98=MockFixedIntBlock(blockSize=1289), d97=MockVariableIntBlock(baseBlockSize=91), d96=MockSep, d95=Pulsing(freqCutoff=15), d99=MockRandom, a20=MockRandom, c99=MockVariableIntBlock(baseBlockSize=91), c98=MockRandom, c97=Pulsing(freqCutoff=15), c96=MockFixedIntBlock(blockSize=1289), b19=MockVariableIntBlock(baseBlockSize=91), a16=SimpleText, a17=Standard, b17=Pulsing(freqCutoff=15), a14=MockRandom, b18=MockSep, a15=MockVariableIntBlock(baseBlockSize=91), a12=MockVariableIntBlock(baseBlockSize=91), a13=MockFixedIntBlock(blockSize=1289), a10=Pulsing(freqCutoff=15), a11=MockSep, b11=MockFixedIntBlock(blockSize=1289), b12=Pulsing(freqCutoff=15), b10=SimpleText, b15=Standard, b16=MockRandom, a18=MockFixedIntBlock(blockSize=1289), b13=MockVariableIntBlock(baseBlockSize=91), a19=Pulsing(freqCutoff=15), b14=MockFixedIntBlock(blockSize=1289), b30=MockSep, a31=Pulsing(freqCutoff=15), a30=MockFixedIntBlock(blockSize=1289), b28=Standard, a25=Pulsing(freqCutoff=15), b29=MockRandom, a26=MockSep, a27=MockVariableIntBlock(baseBlockSize=91), a28=MockFixedIntBlock(blockSize=1289), a21=Standard, a22=MockRandom, a23=MockSep, a24=SimpleText, b20=MockRandom, b21=MockVariableIntBlock(baseBlockSize=91), b22=SimpleText, b23=Standard, a29=SimpleText, b24=MockSep, b25=SimpleText, b26=MockFixedIntBlock(blockSize=1289), b27=Pulsing(freqCutoff=15), b41=MockFixedIntBlock(blockSize=1289), b40=MockVariableIntBlock(baseBlockSize=91), c77=MockRandom, c76=Standard, c75=MockFixedIntBlock(blockSize=1289), c74=MockVariableIntBlock(baseBlockSize=91), c79=Standard, c78=SimpleText, c80=MockVariableIntBlock(baseBlockSize=91), c83=MockSep, c84=SimpleText, c81=Standard, b39=MockSep, c82=MockRandom, b37=MockRandom, b38=MockVariableIntBlock(baseBlockSize=91), b35=MockFixedIntBlock(blockSize=1289), b36=Pulsing(freqCutoff=15), b33=Pulsing(freqCutoff=15), b34=MockSep, b31=SimpleText, b32=Standard, str2=Pulsing(freqCutoff=15), b50=MockRandom, b52=SimpleText, str3=MockRandom, b51=MockSep, c86=SimpleText, tvtest=MockSep, c85=MockSep, c88=Pulsing(freqCutoff=15), c87=MockFixedIntBlock(blockSize=1289), c89=MockVariableIntBlock(baseBlockSize=91), c90=Pulsing(freqCutoff=15), c91=MockSep, c92=MockFixedIntBlock(blockSize=1289), c93=Pulsing(freqCutoff=15), c94=MockRandom, c95=MockVariableIntBlock(baseBlockSize=91), content1=MockSep, b46=SimpleText, b47=Standard, content3=Standard, b48=Pulsing(freqCutoff=15), content4=SimpleText, b49=MockSep, content5=MockRandom, b42=MockVariableIntBlock(baseBlockSize=91), b43=MockFixedIntBlock(blockSize=1289), b44=Standard, b45=MockRandom}, locale=lv_LV, timezone=Australia/Lindeman
NOTE: all tests run in this JVM:
[TestNumericTokenStream, TestIndexFileDeleter, TestIndexInput, TestIndexReaderCloneNorms, TestIndexReaderReopen, TestIndexWriter]
NOTE: FreeBSD 8.2-RELEASE amd64/Sun Microsystems Inc. 1.6.0 (64-bit)/cpus=16,threads=1,free=44228576,total=213778432
{noformat}"
1,"Unable to delete a non session-scoped locked node in XA Environment. You must first add a valid lockToken to the Session and then try to remove this node in a XA Environment.
This will resulting in a NoSuchItemStateException: State has been marked destroyed.
The  problem is that the unlock Operation will be done after that the node has been marked for destroyed.
"
1,"NodeState and NodeStateListener deadlock. 

Java stack information for the threads listed above:
===================================================
""jmssecondaryApplnJobExecutor-8"":
	at org.apache.jackrabbit.core.state.NodeState.getChildNodeEntry(NodeState.java:300)
	- waiting to lock <0x9e6c6d08> (a org.apache.jackrabbit.core.state.NodeState)
	at org.apache.jackrabbit.core.CachingHierarchyManager.nodeModified(CachingHierarchyManager.java:316)
	- locked <0xa09882a8> (a java.lang.Object)
	at org.apache.jackrabbit.core.CachingHierarchyManager.stateModified(CachingHierarchyManager.java:293)
	at org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)
	at org.apache.jackrabbit.core.state.SessionItemStateManager.stateModified(SessionItemStateManager.java:889)
	at org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)
	at org.apache.jackrabbit.core.state.LocalItemStateManager.stateModified(LocalItemStateManager.java:452)
	at org.apache.jackrabbit.core.state.XAItemStateManager.stateModified(XAItemStateManager.java:602)
	at org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyStateModified(StateChangeDispatcher.java:111)
	at org.apache.jackrabbit.core.state.SharedItemStateManager.stateModified(SharedItemStateManager.java:400)
	at org.apache.jackrabbit.core.state.ItemState.notifyStateUpdated(ItemState.java:244)
	at org.apache.jackrabbit.core.state.ChangeLog.persisted(ChangeLog.java:297)
	at org.apache.jackrabbit.core.state.SharedItemStateManager$Update.end(SharedItemStateManager.java:749)
	at org.apache.jackrabbit.core.state.SharedItemStateManager.update(SharedItemStateManager.java:1115)
	at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:351)
	at org.apache.jackrabbit.core.state.XAItemStateManager.update(XAItemStateManager.java:354)
	at org.apache.jackrabbit.core.state.LocalItemStateManager.update(LocalItemStateManager.java:326)
	at org.apache.jackrabbit.core.state.SessionItemStateManager.update(SessionItemStateManager.java:325)
	at org.apache.jackrabbit.core.ItemImpl.save(ItemImpl.java:1111)
	- locked <0x9b1b0be0> (a org.apache.jackrabbit.core.XASessionImpl)
	at org.apache.jackrabbit.core.SessionImpl.save(SessionImpl.java:915)
	at org.apache.jackrabbit.jca.JCASessionHandle.save(JCASessionHandle.java:180)
        ...
	at sun.reflect.GeneratedMethodAccessor1067.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:36)
	at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:243)
	at javax.management.modelmbean.RequiredModelMBean.invokeMethod(RequiredModelMBean.java:1074)
	at javax.management.modelmbean.RequiredModelMBean.invoke(RequiredModelMBean.java:955)
	at org.springframework.jmx.export.SpringModelMBean.invoke(SpringModelMBean.java:88)
	at org.jboss.mx.server.RawDynamicInvoker.invoke(RawDynamicInvoker.java:164)
	at org.jboss.mx.modelmbean.RequiredModelMBeanInvoker.invoke(RequiredModelMBeanInvoker.java:127)
	at org.jboss.mx.server.MBeanServerImpl.invoke(MBeanServerImpl.java:659)
	at org.jboss.system.server.jmx.LazyMBeanServer.invoke(LazyMBeanServer.java:291)
	at javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:288)
	at $Proxy692.doDiscoveryNow(Unknown Source)
        ...
	at org.springframework.jms.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:531)
	at org.springframework.jms.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:466)
	at org.springframework.jms.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:435)
	at org.springframework.jms.listener.AbstractPollingMessageListenerContainer.doReceiveAndExecute(AbstractPollingMessageListenerContainer.java:322)
	at org.springframework.jms.listener.AbstractPollingMessageListenerContainer.receiveAndExecute(AbstractPollingMessageListenerContainer.java:260)
	at org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.invokeListener(DefaultMessageListenerContainer.java:944)
	at org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.run(DefaultMessageListenerContainer.java:868)
	at java.lang.Thread.run(Thread.java:619)
""jmssecondaryApplnJobExecutor-7"":
	at org.apache.jackrabbit.core.CachingHierarchyManager.nodeAdded(CachingHierarchyManager.java:362)
	- waiting to lock <0xa09882a8> (a java.lang.Object)
	at org.apache.jackrabbit.core.state.StateChangeDispatcher.notifyNodeAdded(StateChangeDispatcher.java:159)
	at org.apache.jackrabbit.core.state.SessionItemStateManager.nodeAdded(SessionItemStateManager.java:947)
	at org.apache.jackrabbit.core.state.NodeState.notifyNodeAdded(NodeState.java:882)
	at org.apache.jackrabbit.core.state.NodeState.addChildNodeEntry(NodeState.java:351)
	- locked <0x9e6c6d08> (a org.apache.jackrabbit.core.state.NodeState)
	at org.apache.jackrabbit.core.NodeImpl.createChildNode(NodeImpl.java:541)
	- locked <0xa00619a8> (a org.apache.jackrabbit.core.NodeImpl)
	at org.apache.jackrabbit.core.NodeImpl.internalAddChildNode(NodeImpl.java:802)
	at org.apache.jackrabbit.core.NodeImpl.internalAddNode(NodeImpl.java:735)
	at org.apache.jackrabbit.core.NodeImpl.addNodeWithUuid(NodeImpl.java:2200)
	- locked <0xa00619f8> (a org.apache.jackrabbit.core.NodeImpl)
	at org.apache.jackrabbit.core.NodeImpl.addNode(NodeImpl.java:2133)
	- locked <0xa00619f8> (a org.apache.jackrabbit.core.NodeImpl)
        ...
	at sun.reflect.GeneratedMethodAccessor1067.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:36)
	at sun.reflect.GeneratedMethodAccessor110.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:243)
	at javax.management.modelmbean.RequiredModelMBean.invokeMethod(RequiredModelMBean.java:1074)
	at javax.management.modelmbean.RequiredModelMBean.invoke(RequiredModelMBean.java:955)
	at org.springframework.jmx.export.SpringModelMBean.invoke(SpringModelMBean.java:88)
	at org.jboss.mx.server.RawDynamicInvoker.invoke(RawDynamicInvoker.java:164)
	at org.jboss.mx.modelmbean.RequiredModelMBeanInvoker.invoke(RequiredModelMBeanInvoker.java:127)
	at org.jboss.mx.server.MBeanServerImpl.invoke(MBeanServerImpl.java:659)
	at org.jboss.system.server.jmx.LazyMBeanServer.invoke(LazyMBeanServer.java:291)
	at javax.management.MBeanServerInvocationHandler.invoke(MBeanServerInvocationHandler.java:288)
	at $Proxy692.doDiscoveryNow(Unknown Source)
        ...
	at org.springframework.jms.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:531)
	at org.springframework.jms.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:466)
	at org.springframework.jms.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:435)
	at org.springframework.jms.listener.AbstractPollingMessageListenerContainer.doReceiveAndExecute(AbstractPollingMessageListenerContainer.java:322)
	at org.springframework.jms.listener.AbstractPollingMessageListenerContainer.receiveAndExecute(AbstractPollingMessageListenerContainer.java:260)
	at org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.invokeListener(DefaultMessageListenerContainer.java:944)
	at org.springframework.jms.listener.DefaultMessageListenerContainer$AsyncMessageListenerInvoker.run(DefaultMessageListenerContainer.java:868)
	at java.lang.Thread.run(Thread.java:619)

Found 1 deadlock.

"
1,"spi2davex: Batch fails to create/modify properties with non-ascii characters names. the spi2davex batch implementation fails upon creation/modification of all property types that have their value sent as
separate stringpart or binarypart AND contain non-ascii characters in their property name.

from what i've seen this is due to a limitation in HttpClient 3.x Part#sendDispositionHeader that always writes the part name
as ascii-bytes. in a related discussion [1] specification compliance and usability were addressed.

looking at the server-side part revealed that org.apache.commons.fileupload.FileUploadBase#FileItemIteratorImpl
is prepared to receive non-ascii characters in a header value.
a simple test also showed that curl is perfectly able to send utf-8 part names.

based on this information and given the fact that spi2dav and the server-sided part are intended to communicate
with one other rather than with any kind of custom clients, i suggest to add a simple fix by patching the parts used
within spi2davex.

btw: in HttpClient 4.x there seems to be a workaround for this problem [2]

[1] http://www.mail-archive.com/httpclient-dev@jakarta.apache.org/msg04637.html
[2] https://issues.apache.org/jira/browse/HTTPCLIENT-293"
1,"SetCookie / DateParser failing to parse non-standard date format. I'm receiving the following expiration date in SetCookie which DateParser 
doesn't handle:

expires=Sat,19-Apr-03 04:28:07 GMT

The lack of a space between ',' and '19' is causing the problem. Is it possible 
to add the following lines to DatePattern?

""EEE,dd-MMM-yy HH:mm:ss z""
""EEE,dd-MMM-yyyy HH:mm:ss z"""
1,Add delete term and query need to more precisely record the bytes used. DocumentsWriter's add delete query and add delete term add to the number of bytes used regardless of the query or term already existing in the respective map.
1,"PROPPATCH doesn't respect document order. PROPPATCH is currently implemented in terms of DavResource.alterProperties(...), which takes a set of properties to be set and a set of properties to be removed. This is not sufficient to model WebDAV's method semantics, as the order in which set/remove instructions appear is supposed to be relevant.

I have submitted a patch to the Litmus mailing list checking this (see <http://mailman.webdav.org/pipermail/litmus/2006-April/000196.html>).

In jcr-server, alterProperties probably should be changed to take an (ordered) list of set/remove instructions instead. The simplest approach for that would probably be to use a List containing either DavProperty (set) or DavPropertyName (remove) objects.
"
1,Auth state is not correctly maintained if a successful NTLM authentication results in a redirect. HttpClient fails to update the auth state correctly if a successful NTLM authentication results in a redirect response. Reported by Valentin Popov <valentin.po at gmail.com>
1,"ISO8601 uses default DecimalFormat constructor using locale specific digits. ISO8601.java uses the default DecimalFormat constructor which uses locale specific DecimalFormatSymbols. Runnning Jackrabbit in an Indian locale the format() produces a date using DEVANAGARI numeric digits. The saved version (UTF-8) encoded is much longer than usual and is not transportable. On parsing, DecimalFormat works, but TimeZone.getTimeZone(""GMT+09:30"") (with Indian numeric digits) fails and null is returned from ISO8601. Later this traceback occurs.

2010-02-22 15:14:04,059[http-0.0.0.0-8080-16] ERROR org.apache.jackrabbit.core.persistence.bundle.BundleFsPersistenceManager - failed to write bundle: ff629488-ebb9-4300-a63b-341553cc1140
java.lang.IllegalArgumentException: argument can not be null
	at org.apache.jackrabbit.util.ISO8601.format(ISO8601.java:217)
	at org.apache.jackrabbit.core.value.InternalValue.toString(InternalValue.java:531)
	at org.apache.jackrabbit.core.persistence.bundle.util.BundleBinding.writeState(BundleBinding.java:689)
	at org.apache.jackrabbit.core.persistence.bundle.util.BundleBinding.writeBundle(BundleBinding.java:273)
	at org.apache.jackrabbit.core.persistence.bundle.BundleFsPersistenceManager.storeBundle(BundleFsPersistenceManager.java:664)
	at org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.putBundle(AbstractBundlePersistenceManager.java:703)
	at org.apache.jackrabbit.core.persistence.bundle.AbstractBundlePersistenceManager.store(AbstractBundlePersistenceManager.java:643)


ISO8601 probably meant the chars to be ASCII, and so the constructor with a fixed locale is more appropriate (and this doesn't encounter the TimeZone issue either).

    private static final DecimalFormat XX_FORMAT = new DecimalFormat(""00"", new DecimalFormatSymbols(Locale.US));
    private static final DecimalFormat XXX_FORMAT = new DecimalFormat(""000"", new DecimalFormatSymbols(Locale.US));
    private static final DecimalFormat XXXX_FORMAT = new DecimalFormat(""0000"", new DecimalFormatSymbols(Locale.US));
 "
1,"Request with DIGEST authentication fails when redirected. Request with DIGEST authentication fails when redirected due to invalid URI
parameter.

-- Client side log ----------------------------------------------------------

[DEBUG] HttpClient - -Java version: 1.2.2
[DEBUG] HttpClient - -Java vendor: Sun Microsystems Inc.
[DEBUG] HttpClient - -Operating system name: Linux
[DEBUG] HttpClient - -Operating system architecture: i386
[DEBUG] HttpClient - -Operating system version: 2.4.20-13.9-ok
[DEBUG] HttpClient - -SUN 1.2: SUN (DSA key/parameter generation; DSA signing;
SHA-1, MD5 digests; SecureRandom; X.509 certificates; JKS keystore)
[DEBUG] HttpClient - -SunJSSE 1.0301: Sun JSSE provider(implements RSA
Signatures, PKCS12, SunX509 key/trust factories, SSLv3, TLSv1)
[DEBUG] HttpConnection - -Creating connection for localhost using protocol http:80
[DEBUG] HttpConnection - -HttpConnection.setSoTimeout(0)
[DEBUG] HttpMethod - -Execute loop try 1
[DEBUG] wire - ->> ""GET /transfer HTTP/1.1[\r][\n]""
[DEBUG] HttpMethod - -Adding Host request header
[DEBUG] wire - ->> ""User-Agent: Jakarta Commons-HttpClient/2.0beta1[\r][\n]""
[DEBUG] wire - ->> ""Host: localhost[\r][\n]""
[DEBUG] wire - ->> ""[\r][\n]""
[DEBUG] wire - -<< ""HTTP/1.1 401 Authorization Required[\r][\n]""
[DEBUG] wire - -<< ""Date: Fri, 20 Jun 2003 08:30:06 GMT[\r][\n]""
[DEBUG] wire - -<< ""Server: Apache/2.0.40 (Red Hat Linux)[\r][\n]""
[DEBUG] wire - -<< ""WWW-Authenticate: Digest realm=""guest realm"",
nonce=""ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a"", algorithm=MD5,
domain=""/transfer"", qop=""auth""[\r][\n]""
[DEBUG] wire - -<< ""Vary: accept-language[\r][\n]""
[DEBUG] wire - -<< ""Accept-Ranges: bytes[\r][\n]""
[DEBUG] wire - -<< ""Content-Length: 1285[\r][\n]""
[DEBUG] wire - -<< ""Content-Type: text/html; charset=ISO-8859-1[\r][\n]""
[DEBUG] HttpMethod - -Authorization required
[DEBUG] HttpAuthenticator - -Using 'guest realm' authentication realm
[DEBUG] HttpMethod - -HttpMethodBase.execute(): Server demanded authentication
credentials, will try again.
...
[DEBUG] HttpMethod - -Resorting to protocol version default close connection policy
[DEBUG] HttpMethod - -Should NOT close connection, using HTTP/1.1.
[DEBUG] HttpMethod - -Execute loop try 2
[DEBUG] wire - ->> ""GET /transfer HTTP/1.1[\r][\n]""
[DEBUG] HttpMethod - -Request to add Host header ignored: header already added
[DEBUG] wire - ->> ""User-Agent: Jakarta Commons-HttpClient/2.0beta1[\r][\n]""
[DEBUG] wire - ->> ""Host: localhost[\r][\n]""
[DEBUG] wire - ->> ""Authorization: Digest username=""guest"", realm=""guest realm"",
nonce=""ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a"", uri=""/transfer"",
qop=""auth"", algorithm=""MD5"", nc=00000001,
cnonce=""81d4b905a4e9def944beaed8daf79283"",
response=""71394edcddf4bcee6237ea4bb50cfaa5""[\r][\n]""
[DEBUG] wire - ->> ""[\r][\n]""
[DEBUG] wire - -<< ""HTTP/1.1 301 Moved Permanently[\r][\n]""
[DEBUG] wire - -<< ""Date: Fri, 20 Jun 2003 08:30:06 GMT[\r][\n]""
[DEBUG] wire - -<< ""Server: Apache/2.0.40 (Red Hat Linux)[\r][\n]""
[DEBUG] wire - -<< ""Location: http://localhost/transfer/[\r][\n]""
[DEBUG] wire - -<< ""Content-Length: 302[\r][\n]""
[DEBUG] wire - -<< ""Content-Type: text/html; charset=iso-8859-1[\r][\n]""
[DEBUG] HttpMethod - -Redirect required
[DEBUG] HttpMethod - -Redirect requested to location 'http://localhost/transfer/'
[DEBUG] HttpMethod - -Redirecting from 'http://localhost:80/transfer' to
'http://localhost/transfer/
...
[DEBUG] HttpMethod - -Resorting to protocol version default close connection policy
[DEBUG] HttpMethod - -Should NOT close connection, using HTTP/1.1.
[DEBUG] HttpMethod - -Execute loop try 3
[DEBUG] wire - ->> ""GET /transfer/ HTTP/1.1[\r][\n]""
[DEBUG] HttpMethod - -Request to add Host header ignored: header already added
[DEBUG] wire - ->> ""User-Agent: Jakarta Commons-HttpClient/2.0beta1[\r][\n]""
[DEBUG] wire - ->> ""Host: localhost[\r][\n]""
[DEBUG] wire - ->> ""Authorization: Digest username=""guest"", realm=""guest realm"",
nonce=""ei+T7oPAAwA=53c8e6d609ff81a8dcbc370b51f8aadec565009a"", uri=""/transfer"",
qop=""auth"", algorithm=""MD5"", nc=00000001,
cnonce=""81d4b905a4e9def944beaed8daf79283"",
response=""71394edcddf4bcee6237ea4bb50cfaa5""[\r][\n]""
[DEBUG] wire - ->> ""[\r][\n]""
[DEBUG] wire - -<< ""HTTP/1.1 400 Bad Request[\r][\n]""
[DEBUG] wire - -<< ""Date: Fri, 20 Jun 2003 08:30:06 GMT[\r][\n]""
[DEBUG] wire - -<< ""Server: Apache/2.0.40 (Red Hat Linux)[\r][\n]""
[DEBUG] wire - -<< ""Vary: accept-language[\r][\n]""
[DEBUG] wire - -<< ""Accept-Ranges: bytes[\r][\n]""
[DEBUG] wire - -<< ""Content-Length: 973[\r][\n]""
[DEBUG] wire - -<< ""Connection: close[\r][\n]""
[DEBUG] wire - -<< ""Content-Type: text/html; charset=ISO-8859-1[\r][\n]""

-- End of client side log -----------------------------------------------------


-- Server side log ------------------------------------------------------------

[Fri Jun 20 10:30:06 2003] [error] [client 127.0.0.1] Digest: uri mismatch -
</transfer> does not match request-uri </transfer/>

-- End of server side log -----------------------------------------------------"
1,Fix exception handling and thread safety in realtime branch. Several tests are currently failing in the realtime branch - most of them due to thread safety problems (often exceptions in ConcurrentMergeScheduler) and in tests that test for aborting and non-aborting exceptions.
1,"MatchAllScorer calculateDocFilter() bug. In MatchAllScorer.calculateDocFilter(), When you have just two nodes, with different properties, like ""myprop"" and ""myprop2"", and you have an xpath String xpath = ""//*[@myprop], you get both nodes back (to be precise, you'll get every node that has a property that startswith ""myprop"")


You can reproduce it by changing the SimpleQueryTest.testIsNotNull() a little:

Change 

bar.setProperty(""text"", ""the quick brown fox jumps over the lazy dog.""); 

to

bar.setProperty(""mytextwhichstartswithmytext"", ""the quick brown fox jumps over the lazy dog."");

Now the test with xpath = ""//*[@jcr:primaryType='nt:unstructured' and @mytext]""; fails because 2 results. I did test for the trunk and tag 1.3.1 and both have the same problem. I have attached MatchAllScorer.java.patch in this mail, or should I create a JIRA issue for this? 

Furthermore I would like to discuss a different implementation for the MatchAllScorer, because IMHO the current calculateDocFilter() becomes slow pretty fast (see bottom email the code part i am referring to: if you have 100.000 docs with ""mytext"" property, and you query  [@mytext] the loop below is executed at least 100.000 times). I think it might be out of scope for the user-list, or is the user-list the place to discuss something like this? 

-----------------------------------------------------------------------

TermEnum terms = reader.terms(new Term(FieldNames.PROPERTIES, field));
        try {
            TermDocs docs = reader.termDocs();
            try {
                while (terms.term() != null
                        && terms.term().field() == FieldNames.PROPERTIES
                        && terms.term().text().startsWith(field)) {
                    docs.seek(terms);
                    while (docs.next()) {
                        docFilter.set(docs.doc());
                    }
                    terms.next();
                }
            } finally {
                docs.close();
            }
        } finally {
            terms.close();
        }

-----------------------------------------------------------------------

"
0,add test case for recovering from broken version history hierarchy. The test should exercise recovery from a missing parent node of a VHR.
0,"Session#importXML can't handle properly uuid collision if user has insufficient permission. When importing referenceable nodes, if there are nodes with the same uuid in the workspace but the session has no sufficient permission to read them then the import will fail no matter what ImportUUIDBehavior is chosen. 
But the same xml will be imported successfully in another repository or if the user have read access.

SessionImpl.java :
 public NodeImpl getNodeById(NodeId id) ...{
...
 try {
            return (NodeImpl) getItemManager().getItem(id);
        } catch (AccessDeniedException ade) {
            throw new ItemNotFoundException(id.toString());
        }
}

SessionImporter.java :

 public void startNode(NodeInfo nodeInfo, List propInfos)...{
...
  if (node == null) {
            // create node
            if (id == null) {
            ...
            } else {
                // potential uuid conflict
                NodeImpl conflicting;
                try {
                    conflicting = session.getNodeById(id);
                } catch (ItemNotFoundException infe) {
                    conflicting = null;
                }
                if (conflicting != null) {
                    // resolve uuid conflict
                 ...
               }
...
}

In the JCR 1.0 spec says ""lack of read access to an item blocks access to both information about the content of that item and information about the existence of the item"" but this should probably not be true, internally, when doing an import. 
Otherwise it means that read access to an entire workspace must be granted to a user so that it could successfully use the IMPORT_UUID_CREATE_NEW behaviour.

"
0,"Provide possibility to import protected items using Session import functionality. SessionImporter and WorkspaceImporter currently skip all protected items encountered during import except for some special cases
(see JCR-2172 and WorkspaceImporter#postProcessNode).
The specification only mandates that protected content is treated in a consistent manner, but allows the implementation to either import or ignore it.

Find attached a patch containing some initials steps to allow to extend the default import behavior:
Instead of skipping protected items (and in case of nodes the complete tree below it), they should be passed to a separate handler,
that may or may not be able to deal with them and needs to assert, that they are in a valid format.

The patch includes:

- Abstract classes for that protected item import
- Default implementations that never import protected nodes (same behavior as we have today)
- An example implementation for the AC-content (just to see if it works for simple cases) + some trivial tests.
- Changes to SessionImporter to demonstrate how import of protected items would be enabled.

The patch doesn't include yet:

- Changes to WorkspaceImporter (would +- be according to SessionImporter)
- Changes to WorkspaceImpl/SessionImpl as well as configuration that would allow to modify the default behavior.
- Examples for import of protected properties.
- Examples for workspace import.

The patch has the following limitations or TODOs:

- Proper handling of protected references properties or non-protected ref properties with the tree defined by a protected node.
- Test / Careful review if the various ImportUUIDBehaviors are/can properly be covered, specially in case of ""replace-existing"".

The patch in addition addresses:

- An inconsistency in the SessionImporter:
  > Attempt to import protected content below an existing protected node => skipped
  > Attempt to import protected content that doesn't yet exist => first node is imported, ConstraintViolationException for child-nodes.
  > This behavior is also reflected in the Node-stack... where in the first case 'null' is pushed, in the second case the first protected node.
     (see also JCR-2172 for details).
"
0,"Minor typo in org.apache.commons.httpclient.Wire 2.0-rc1. Minor typo ""...may noy be null"" in 
public static final void output(final String s) and
public static final void input(final String s)
of org.apache.commons.httpclient.Wire."
0,"filter jcr properties in jcr-server. attached is a patch that implements jcr property filtering in jcr-server in the same way that nodes and resources are filtered. with the default filter configuration, this has the effect of filtering jcr:created, jcr:mixinTypes, and jcr:primaryType from nt:folder and nt:file nodes. 

this is likely the expected default behavior for most webdav servers - they want to return the normal dav properties, live properties defined themselves, and dead properties defined by clients, but not jcr-internal properties which are for all intents and purposes implementation-specific."
0,Snowball package contains BSD licensed code with ASL header. All classes in org.tartarus.snowball (but not in org.tartarus.snowball.ext) has for some reason been given an ASL header. These classes are licensed with BSD. Thus the ASL header should be removed. I suppose this a misstake or possible due to the ASL header automation tool.
0,"Reduce log level in MultiIndex for deleting obsolete index. The MultiIndex class issues a logging message (with info level) that the obsolete index cannot be deleted (quite often).
As the segments are deleted later (with a retry) and this ""warning"" can be ignored (http://dev.day.com/kb/content/wiki/kb/Crx/Troubleshooting/UnableToDeleteObsoleteIndex.html ), it would be nice to reduce the logging level to debug. People, who are maintaining projects, are not aware of Jackarabbit details and are sometimes scared about this ""warning"" :-)

Thank you in advance!

Kind regards
Sergiy"
0,"Reusable Repository access and bind servlets. As discussed in http://mail-archives.apache.org/mod_mbox/jackrabbit-dev/200705.mbox/%3C510143ac0705151453t7a0eb4cam859a40fb106e81f5@mail.gmail.com%3E and JCR-955, it would be useful to have a reusable set of servlet components for accessing and exposing repositories in various configurable ways.

My plan is to refactor the current RepositoryAccessServlet from jackrabbit-webapp and place the resulting servlet components in jackrabbit-jcr-commons, with servlet-api as a new optional (or provided) dependency."
0,Make inspection of BooleanQuery more efficient. Just attempting to inspect a BooleanQuery allocates two new arrays.  This could be cheaper.
0,JCR2SPI: Use namespace decl. present in imported xml to resolve Name/Path values. 
0,"HyphenationCompoundWordTokenFilter fails to load DTD in Crimson parser (JDK 1.4). HyphenationCompoundWordTokenFilter loads the DTD in its XML parser from memory by supplying EntityResolver. In Java 1.4 (affects Lucene 2.9, but also later versions if not Apache Xerces is used as XML parser) this does not work, because Cromson does not even ask the entity resolver, if no base URI is known. As the hyphenation file is loaded from Reader/InputStream no base URI is known. Crimson needs at least a non-null systemId to proceed.

This patch (Lucene 2.9 only)  fakes this by supplying a fake systemId to the InputSource."
0,"New Analyzer for buffering tokens. In some cases, it would be handy to have Analyzer/Tokenizer/TokenFilters that could siphon off certain tokens and store them in a buffer to be used later in the processing pipeline.

For example, if you want to have two fields, one lowercased and one not, but all the other analysis is the same, then you could save off the tokens to be output for a different field.

Patch to follow, but I am still not sure about a couple of things, mostly how it plays with the new reuse API.

See http://www.gossamer-threads.com/lists/lucene/java-dev/54397?search_string=BufferingAnalyzer;#54397"
0,"optimizations for bufferedindexinput. along the same lines as LUCENE-2816:
* the readVInt/readVLong/readShort/readInt/readLong are not optimal here since they defer to readByte. for example this means checking the buffer's bounds per-byte in readVint instead of per-vint.
* its an easy win to speed this up, even for the vint case: its essentially always faster, the only slower case is 1024 single-byte vints in a row, in this case we would do a single extra bounds check (1025 instead of 1024)
"
0,"exceptions from other threads in beforeclass/etc do not fail the test. Lots of tests create indexes in beforeClass methods, but if an exception is thrown from another thread
it won't fail the test... e.g. this test passes:
{code}
public class TestExc extends LuceneTestCase {
  @BeforeClass
  public static void beforeClass() {
    new Thread() {
      public void run() {
        throw new RuntimeException(""boo!"");
      }  
    }.start();
  }
  
  public void test() { }
}
{code}

this is because the uncaught exception handler is in setup/teardown"
0,"User/Developer Documentation. - quotes from user's on why they used it.
- better project docs, including checkstyle and clover reports, and changelog
- examples showing how to configure logging and why you may want to
- Links on HttpClient to 'sister' projects such as Slide, Cactus and Latka to
show where how it's being used."
0,"spi2dav Improve performance for large binary properties. Sending large binary properties over spi2dav is slow and requires a lot of heap space in both client and server.
One problematic part is base64 conversion of the property value.

On the contrary, using 'normal' webdav interface (/repository/default/ instead of /server) for uploading a file (through traditional webdav client) it is pretty fast and don't have such impact on heap space.

Some suggestions from the previous discussion:
 - avoid temporary copies of the data, and persist large objects as early as possible. 
 - transfer large objects in blocks from the Jackrabbit SPI client to the server (and back).
 - make usage of the global data store (JCR-926). 
 - straight forward PUT for single-valued properties

Link to discussion: http://www.mail-archive.com/dev@jackrabbit.apache.org/msg09481.html
"
0,"System Reqs page should be release specific. The System Requirements page, currently under the Main->Resources section of the website should be part of a given version's documentation, since it will be changing for a given release.  

I will ""deprecate"" the existing one, but leave it in place(with a message) to cover the existing releases that don't have this, but will also add it to the release docs for future releases."
0,"Can not subscribe. Hello, 
I have sent email to lucene-dev-subscribe@jakarta.apache.org and it always 
returns failed: 
 
<lucene-dev-subscribe@jakarta.apache.org>: 
Sorry, no mailbox here by that name. (#5.1.1) 
 
Please help me subscribe."
0,"create a simple test that indexes and searches byte[] terms. Currently, the only good test that does this is Test2BTerms (disabled by default)

I think we should test this capability, and also have a simpler example for how to do this.
"
0,"Upgrade to latest Apache parent POM. We're quite a bit behind the latest and greatest of the Apache parent POMs (org.apache:apache), mostly since we're inheriting it through the now mostly unused org.apache.jackrabbit:parent POM.

I'd like to move things back from the o.a.j:parent POM to the jackrabbit-parent POM that's located inside trunk. This will allow us to upgrade to the latest Apache parent POM without the trouble of an extra release of the o.a.j:parent POM."
0,"Change Visibility of fields[] in MultiFieldQueryParser. In MultiFieldQueryParser the two methods 

  protected Query getFuzzyQuery(String field, String termStr, float minSimilarity) throws ParseException
  protected Query getWildcardQuery(String field, String termStr) throws ParseException

are intended to be overwritten if one would like to avoid fuzzy and wildcard queries. However, the String[] fields attribute of this class is private and hence it is not accessible in subclasses of MFQParser. If you just change it to protected this issue should be solved."
0,"remove 1.5 only unit test code that snuck in. I just tried to run unit tests w/ Java 1.4.2, but hit this:

{code}
common.compile-test:
    [mkdir] Created dir: /lucene/src/diagnostics.1654/build/classes/test
    [javac] Compiling 191 source files to /lucene/src/diagnostics.1654/build/classes/test
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:26: package java.util.concurrent.atomic does not exist
    [javac] import java.util.concurrent.atomic.AtomicInteger;
    [javac]                                    ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:262: cannot resolve symbol
    [javac] symbol  : class AtomicInteger 
    [javac] location: class org.apache.lucene.index.TestIndexWriterReader.DeleteThreads
    [javac]     AtomicInteger delCount = new AtomicInteger();
    [javac]     ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:332: cannot resolve symbol
    [javac] symbol  : class AtomicInteger 
    [javac] location: class org.apache.lucene.index.TestIndexWriterReader.AddDirectoriesThreads
    [javac]     AtomicInteger count = new AtomicInteger(0);
    [javac]     ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:333: cannot resolve symbol
    [javac] symbol  : class AtomicInteger 
    [javac] location: class org.apache.lucene.index.TestIndexWriterReader.AddDirectoriesThreads
    [javac]     AtomicInteger numAddIndexesNoOptimize = new AtomicInteger(0);
    [javac]     ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:262: cannot resolve symbol
    [javac] symbol  : class AtomicInteger 
    [javac] location: class org.apache.lucene.index.TestIndexWriterReader.DeleteThreads
    [javac]     AtomicInteger delCount = new AtomicInteger();
    [javac]                                  ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:332: cannot resolve symbol
    [javac] symbol  : class AtomicInteger 
    [javac] location: class org.apache.lucene.index.TestIndexWriterReader.AddDirectoriesThreads
    [javac]     AtomicInteger count = new AtomicInteger(0);
    [javac]                               ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/index/TestIndexWriterReader.java:333: cannot resolve symbol
    [javac] symbol  : class AtomicInteger 
    [javac] location: class org.apache.lucene.index.TestIndexWriterReader.AddDirectoriesThreads
    [javac]     AtomicInteger numAddIndexesNoOptimize = new AtomicInteger(0);
    [javac]                                                 ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/search/TestSort.java:932: cannot resolve symbol
    [javac] symbol  : method getSimpleName ()
    [javac] location: class java.lang.Class
    [javac]           assertEquals(actualTFCClasses[j], tdc.getClass().getSimpleName());
    [javac]                                                         ^
    [javac] /lucene/src/diagnostics.1654/src/test/org/apache/lucene/search/TestTopScoreDocCollector.java:70: cannot resolve symbol
    [javac] symbol  : method getSimpleName ()
    [javac] location: class java.lang.Class
    [javac]         assertEquals(actualTSDCClass[i], tdc.getClass().getSimpleName());
    [javac]                                                      ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -deprecation for details.
    [javac] 9 errors
{code}"
0,"PersistenceManager API change breaks backward compatibility. Persistence Manager API change introduced in JCR-1428 breaks backward compatibility. although this is not a public visible API it renders 3rd party PMs invalid that do not extend from AbstractPersistenceManager.
at least for the 1.4.3 patch release, we should not do this.

suggest to revert the API change for the next 1.4.4 release, but leave the method on the abstract pm, and introduce it only for 1.5.
"
0,"Changes.html formatting improvements. Some improvements to the Changes.html generated by the changes2html.pl script via the 'changes-to-html' ant task:

# Simplified the Simple stylesheet (removed monospace font specification) and made it the default.  The Fancy stylesheet is really hard for me to look at (yellow text on light blue background may provide high contrast with low eye strain, but IMHO it's ugly).
# Moved the monospace style from the Simple stylesheet to a new stylesheet named ""Fixed Width""
# Fixed syntax errors in the Fancy stylesheet, so that it displays as intended.
# Added <span style=""attrib"">  to change attributions.
# In the Fancy and Simple stylesheets, change attributions are colored dark green.
# Now properly handling change attributions in CHANGES.txt that have trailing periods.
# Clicking on an anchor to expand its children now changes the document location to show the children.
# Hovering over anchors now causes a tooltip to be displayed - either ""Click to expand"" or ""Click to collapse"" - the tooltip changes appropriately after a collapse or expansion."
0,"Some Lucene tests try and use a Junit Assert in new threads. There are a few cases in Lucene tests where JUnit Asserts are used inside a new threads run method - this won't work because Junit throws an exception when a call to Assert fails - that will kill the thread, but the exception will not propagate to JUnit - so unless a failure is caused later from the thread termination, the Asserts are invalid.

TestThreadSafe
TestStressIndexing2
TestStringIntern"
0,"Random Failure TestSizeBoundedOptimize#testFirstSegmentTooLarge. I am seeing this on trunk  

{noformat}

[junit] Testsuite: org.apache.lucene.index.TestSizeBoundedOptimize
    [junit] Testcase: testFirstSegmentTooLarge(org.apache.lucene.index.TestSizeBoundedOptimize):	FAILED
    [junit] expected:<2> but was:<1>
    [junit] junit.framework.AssertionFailedError: expected:<2> but was:<1>
    [junit] 	at org.apache.lucene.util.LuceneTestCase$LuceneTestCaseRunner.runChild(LuceneTestCase.java:882)
    [junit] 	at org.apache.lucene.util.LuceneTestCase$LuceneTestCaseRunner.runChild(LuceneTestCase.java:848)
    [junit] 	at org.apache.lucene.index.TestSizeBoundedOptimize.testFirstSegmentTooLarge(TestSizeBoundedOptimize.java:160)
    [junit] 
    [junit] 
    [junit] Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 0.658 sec
    [junit] 
    [junit] ------------- Standard Output ---------------
    [junit] NOTE: reproduce with: ant test -Dtestcase=TestSizeBoundedOptimize -Dtestmethod=testFirstSegmentTooLarge -Dtests.seed=7354441978302993522:-457602792543755447 -Dtests.multiplier=3
    [junit] NOTE: test params are: codec=Standard, locale=sv_SE, timezone=Mexico/BajaNorte
    [junit] ------------- ---------------- ---------------
    [junit] ------------- Standard Error -----------------
    [junit] NOTE: all tests run in this JVM:
    [junit] [TestSizeBoundedOptimize]
    [junit] ------------- ---------------- ---------------
    [junit] Test org.apache.lucene.index.TestSizeBoundedOptimize FAILED
{noformat}

when running with this seed
ant test -Dtestcase=TestSizeBoundedOptimize -Dtestmethod=testFirstSegmentTooLarge -Dtests.seed=7354441978302993522:-457602792543755447 -Dtests.multiplier=3"
0,"Make ShingleAnalyzerWrapper and PerFieldAnalyzerWrapper immutable. Both ShingleAnalyzerWrapper and PerFieldAnalyzerWrapper have setters which change some state which impacts their analysis stack.  If these are going to become reusable, then the state must be immutable as changing it will have no effect.

Process will be similar to QueryAutoStopWordAnalyzer, I will remove in trunk and deprecate in 3x."
0,"provide an ehcache implementation for HttpCache. Provide an implementation of the HttpCache interface that stores cache entries in ehcache.
"
0,"Move tika-parsers dependency to deployment packages. As discussed on the mailing list, it would be better if the tika-parsers dependency (and all the parser libraries it pulls in transitively) was included in our deployment packages but not directly in jackrabbit-core. This would make it easier for people to set up custom lightweight deployments with no or only partial full text extraction functionality.

To do this we'll first need to wait for Tika 0.9, as we currently have a custom PDFParser class in jackrabbit-core as a workaround to a problem in Tika 0.8.

At the same time we should do a more thorough review of the transitive parser dependencies we include. At least the rome and bouncycastle libraries were flagged as potentially unnecessary."
0,"Remove GCJ IndexReader specializations. These specializations are outdated, unsupported, most probably pointless due to the speed of modern JVMs and, I bet, nobody uses them (Mike, you said you are going to ask people on java-user, anybody replied that they need it?). While giving nothing, they make SegmentReader instantiation code look real ugly.

If nobody objects, I'm going to post a patch that removes these from Lucene."
0,"jcr2spi: avoid unnecessary roundtrips with NodeEntry.getPropertyEntry. Since NodeInfo.getPropertyIds always returns the complete set of property names, there is no need for an extra round trip to the SPI upon NodeEntry.getPropertyEntry. The corresponding code could be simplified."
0,"changed behavior of javax.jcr.Value get* methods. stream handling semantics of javax.jcr.Value has been simplified in JCR 2.0:

Section '5.10.5.1 Deprecated Binary Behavior'

[...]
Unlike in JCR 1.0, calling a get method other than getStream before 
calling getStream on the same Value object will never cause an 
IllegalStateException. 


see https://jsr-283.dev.java.net/issues/show_bug.cgi?id=658"
0,"Lucene-core 2.9.0 missing from Maven Central Repository. Sub-projects like lucene-demos, lucene-contrib, etc. exist in central, and depend on 2.9.0 of lucene-core. However, the lucene-core 2.9.0 artifact itself is missing."
0,"Build.xml - add log level definitions. The default log level is debug, which produces quite a lot of output when testing.

The patch allows separate definition of wire and other log levels (assuming SimpleLog is used)"
0,"String constants should be final. RFC2109Spec - SET_COOKIE_KEY

RFC2965Spec - SET_COOKIE2_KEY

both should be final."
0,"Create merge policy that doesn't periodically inadvertently optimize. The current merge policy, at every maxBufferedDocs *
power-of-mergeFactor docs added, will do a fully cascaded merge, which
is the same as an optimize.

I think this is not good because at that ""optimization poin"", the
particular addDocument call is [surprisingly] very expensive.  While,
amortized over all addDocument calls, the cost is low, the cost is
paid ""up front"" and in a very ""bunched up"" manner.

I think of this as ""pay it forward"": you are paying the full cost of
an optimize right now on the expectation / hope that you will be
adding a great many more docs.  But, if you don't add that many more
docs, then, the amortized cost for your index is in fact far higher
than it should have been.  Better to ""pay as you go"" instead.

So we could make a small change to the policy by only merging the
first mergeFactor segments once we hit 2X the merge factor.  With
mergeFactor=10, when we have created the 20th level 0 (just flushed)
segment, we merge the first 10 into a level 1 segment.  Then on
creating another 10 level 0 segments, we merge the second set of 10
level 0 segments into a level 1 segment, etc.

With this new merge policy, an index that's a bit bigger than a
current ""optimization point"" would then have a lower amortized cost
per document.  Plus the merge cost is less ""bunched up"" and less ""pay
it forward"": instead you pay for what you are actually using.

We can start by creating this merge policy (probably, combined with
with the ""by size not by doc count"" segment level computation from
LUCENE-845) and then later decide whether we should make it the
default merge policy.
"
0,"Replace license headers with new policy text. We need to replace all of the license headers with a new template
that replaces the Copyright and license lines with

---BEGIN PROPOSED SOURCE FILE HEADER---
  Licensed to the Apache Software Foundation (ASF) under one or more
  contributor license agreements.  The ASF licenses this file to You
  under the Apache License, Version 2.0 (the ""License""); you may not
  use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an ""AS IS"" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
---END PROPOSED SOURCE FILE HEADER---

The copyright line is being removed from files due to legal advice from ASF attorneys.
It is replaced with a statement that the copyright owners have licensed it to the ASF.
"
0,"common interface for HttpRoute and RouteTracker. Classes HttpRoute and RouteTracker have many identical getters. There should be a common interface, for example RouteInfo, to define these getters and a toRoute() method that returns an unmodifiable representation. Some portions of the API may then accept the interface instead of the specific class HttpRoute.
"
0,"Trim whitespace from parameter names in configuration files. We've had a couple of issues with extra whitespace in parameter names causing those configuration options being lost. Now with the more strict validation of configuration settings such mistakes can even prevent the repository from starting. On one hand that's a good thing, as the user would then explicitly need to fix such broken configurations, but it would be nice if no user intervention was needed.

Since leading and trailing whitespace is never allowed in parameter names, we can just as well trim it automatically."
0,"Add more methods to manipulate QueryNodeProcessorPipeline elements. QueryNodeProcessorPipeline allows the user to define a list of processors to process a query tree. However, it's not very flexible when the user wants to extend/modify an already created pipeline, because it only provides an add method, which only allows the user to append a new processor to the pipeline.

So, I propose to add new methods to manipulate the processor in a pipeline. I think the methods should not consider an index position when modifying the pipeline, hence the index position in a pipeline does not mean anything, a processor has a meaning when it's after or before another processor. Therefore, I suggest the methods should always consider another processor when inserting/modifying the pipeline. For example, insertAfter(processor, newProcessor), which will insert the ""newProcessor"" after the ""processor""."
0,"improve windows defaults in FSDirectory. Currently windows defaults to SimpleFSDirectory, but this is a problem due to the synchronization.

I have been benchmarking queries *sequentially* and was pretty surprised at how much faster
MMapDirectory is, for example for cases that do many seeks.

I think we should change the defaults for windows as such:

if (WINDOWS and UNMAP_SUPPORTED and 64-bit)
  use MMapDirectory
else
  use SimpleFSDirectory 

I think we should just consider doing this for 4.0 only and see how it goes.
"
0,"Cookie.compare(...) uses single instance STRING_COLLATOR to do blocking compares. I am using a MultiThreadedHttpConnectionManager with a single HttpClient instance and multiple GetMethod objects.  I have a 500 thread max.  I recently noticed that all 500 threads are in the same place and seem to be blocking each other - the stack trace is below.  I dug into the Cookie.compare(...) method and saw that it is using STRING_COLLARTOR.compare(c1.getPath(), c2.getPath()).  STRING_COLLATOR is defined as a single instance object, 'private static final RuleBasedCollator STRING_COLLATOR = (RuleBasedCollator) RuleBasedCollator.getInstance(new Locale(""en"", ""US"", """"));'.  I also saw that RuleBasedCollator.compare is synchronized.  That means that every thread that is trying to make a request is getting blocked while it tries to add cookies to the request method.  I do not see a workaround because this is the same static final object in every Cookie instance.  So, the more threads, the more synchronized comparisons.  At times I am fetching URLs all from the same site so I am going through this code a lot.  I need it to be much faster than it currently is because all of my threads are getting eaten up on this call and backlogging my system.  Can a different RuleBasedCollator be used for each compare (use the RuleBasedCollator.getInstance() for every compare?  I think that would solve things.

Name: pool-1-thread-1443: 72.21.206.5
State: BLOCKED on java.text.RuleBasedCollator@190330a owned by: pool-1-thread-1867: 72.21.206.5
Total blocked: 9,598  Total waited: 381

Stack trace: 
java.text.RuleBasedCollator.compare(RuleBasedCollator.java:396)
org.apache.commons.httpclient.Cookie.compare(Cookie.java:484)
org.apache.commons.httpclient.cookie.CookieSpecBase.addInPathOrder(CookieSpecBase.java:578)
org.apache.commons.httpclient.cookie.CookieSpecBase.match(CookieSpecBase.java:557)
org.apache.commons.httpclient.HttpMethodBase.addCookieRequestHeader(HttpMethodBase.java:1179)
org.apache.commons.httpclient.HttpMethodBase.addRequestHeaders(HttpMethodBase.java:1305)
org.apache.commons.httpclient.HttpMethodBase.writeRequestHeaders(HttpMethodBase.java:2036)
org.apache.commons.httpclient.HttpMethodBase.writeRequest(HttpMethodBase.java:1919)
org.apache.commons.httpclient.HttpMethodBase.execute(HttpMethodBase.java:993)
org.apache.commons.httpclient.HttpMethodDirector.executeWithRetry(HttpMethodDirector.java:397)
org.apache.commons.httpclient.HttpMethodDirector.executeMethod(HttpMethodDirector.java:170)
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:396)
org.apache.commons.httpclient.HttpClient.executeMethod(HttpClient.java:324)"
0,"Redesign SPI observation. With the current SPI observation design it may happen that events are lost while the filter for an event listener is changed.

See:
- http://www.nabble.com/SPI-observation%3A-EventFilter-lifecycle-tf4732281.html
- http://people.apache.org/~mreutegg/spi-event/problem.png

My proposal is to introduce a Subscription interface. See attached patch and:
http://people.apache.org/~mreutegg/spi-event/proposal.png"
0,"FST should allow controlling how hard builder tries to share suffixes. Today we have a boolean option to the FST builder telling it whether
it should share suffixes.

If you turn this off, building is much faster, uses much less RAM, and
the resulting FST is a prefix trie.  But, the FST is larger than it
needs to be.  When it's on, the builder maintains a node hash holding
every node seen so far in the FST -- this uses up RAM and slows things
down.

On a dataset that Elmer (see java-user thread ""Autocompletion on large
index"" on Jul 6 2011) provided (thank you!), which is 1.32 M titles
avg 67.3 chars per title, building with suffix sharing on took 22.5
seconds, required 1.25 GB heap, and produced 91.6 MB FST.  With suffix
sharing off, it was 8.2 seconds, 450 MB heap and 129 MB FST.

I think we should allow this boolean to be shade-of-gray instead:
usually, how well suffixes can share is a function of how far they are
from the end of the string, so, by adding a tunable N to only share
when suffix length < N, we can let caller make reasonable tradeoffs. 
"
0,"Land DocValues on trunk. Its time to move another feature from branch to trunk. I want to start this process now while still a couple of issues remain on the branch. Currently I am down to a single nocommit (javadocs on DocValues.java) and a couple of testing TODOs (explicit multithreaded tests and unoptimized with deletions) but I think those are not worth separate issues so we can resolve them as we go. 
The already created issues (LUCENE-3075 and LUCENE-3074) should not block this process here IMO, we can fix them once we are on trunk. 

Here is a quick feature overview of what has been implemented:
 * DocValues implementations for Ints (based on PackedInts), Float 32 / 64, Bytes (fixed / variable size each in sorted, straight and deref variations)
 * Integration into Flex-API, Codec provides a PerDocConsumer->DocValuesConsumer (write) / PerDocValues->DocValues (read) 
 * By-Default enabled in all codecs except of PreFlex
 * Follows other flex-API patterns like non-segment reader throw UOE forcing MultiPerDocValues if on DirReader etc.
 * Integration into IndexWriter, FieldInfos etc.
 * Random-testing enabled via RandomIW - injecting random DocValues into documents
 * Basic checks in CheckIndex (which runs after each test)
 * FieldComparator for int and float variants (Sorting, currently directly integrated into SortField, this might go into a separate DocValuesSortField eventually)
 * Extended TestSort for DocValues
 * RAM-Resident random access API plus on-disk DocValuesEnum (currently only sequential access) -> Source.java / DocValuesEnum.java
 * Extensible Cache implementation for RAM-Resident DocValues (by-default loaded into RAM only once and freed once IR is closed) -> SourceCache.java
 
PS: Currently the RAM resident API is named Source (Source.java) which seems too generic. I think we should rename it into RamDocValues or something like that, suggestion welcome!   


Any comments, questions (rants :)) are very much appreciated."
0,cutover oal.index.* tests to use a random IWC to tease out bugs. 
0,"SimpleSelectionTest assumes RowIterator.getSize() not to return -1. Test case ""testSingleProperty"" assumes that RowIterator.getSize() will not return -1. This is an incorrect assumption, according to the JavaDoc for RangeIterator.

Suggested change:

        long size = result.getRows().getSize();
        if (size != -1) {
            assertEquals(""Should have only 1 result"", 1, size);
        }
"
0,"Clone support. It would be nice to have a clone method for some of the classes that don't have getters & setters exposed for all of their fields. Where relevant, the clone method could be in the interface, so that it doesn't matter which implementing class is being used. The main interfaces that I would like to clone are HttpRequest and Cookie. I know that HttpRequest is technically part of HttpCore, but the primary implementations of it are in HttpClient, so I thought I would post it here. 

Thanks,
David Byrne"
0,"MultiThreadedConnectionManager should provide a shutdown. MultiThreadedConnectionManager should provide a shutdown() method to release 
all its resources, it is currently using daemon threads that cannot be stopped 
and HTTP connections that cannot be released.
This is annoying when the pool of connection is created within a web 
application that is undeployed and re-deployed (i.e. the JVM is not restarted) 
consuming resources on local and remote servers."
0,"[PATCH] retain exception stack traces. Code catches one exception, and throws another, losing the stack trace information of the causal exception. This makes it more difficult to understand what happened when an exception occurs. This patch retains all stack traces that occur that causes a thrown exception."
